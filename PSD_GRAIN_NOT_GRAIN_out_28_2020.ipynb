{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_GRAIN_NOT_GRAIN_out_28_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/marquesgabi_out_2020/blob/main/PSD_GRAIN_NOT_GRAIN_out_28_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZEvJvfoibE4",
        "outputId": "db30d4ec-6dc3-428d-db91-6a3565ad5f9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mahotas in /usr/local/lib/python3.6/dist-packages (1.4.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mahotas) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VcTdaNVh9EE",
        "outputId": "e95da9cf-5a0b-41d8-ef0a-aa53699a94da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_fev_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_a6PJ1iUnT"
      },
      "source": [
        "import mahotas.features.texture as mht\n",
        "import mahotas.features"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj62HANgnpnR",
        "outputId": "00c36fac-434d-493d-b93f-d2b589a07245",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_out_2020/\n",
        "%cd marquesgabi_out_2020\n",
        "\n",
        "from Get_PSDArea import PSDArea\n",
        "from histogram import PSD\n",
        "from GetBetterSegm import GetBetter"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_out_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/marquesgabi_out_2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L6KJ4jc3ahG",
        "outputId": "9f9b9062-542b-4dcc-c44e-9fa495b3a699",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Areas_ImageJ.csv\t\t imageJ_jpg.zip\n",
            "Areas_ImageJ.xlsx\t\t IMAGEJ_Zuados.zip\n",
            "Doutorado\t\t\t PSD_GRAIN_NOT_GRAIN_out_09_2020.ipynb\n",
            "GetBetterSegm.py\t\t PSD_GRAIN_NOT_GRAIN_out_19_2020.ipynb\n",
            "Get_PSDArea.py\t\t\t PSD_USA_ROTINAS_out_05_2020.ipynb\n",
            "Histogram_PSD_out_19_2020.ipynb  __pycache__\n",
            "Histogram_PSD_out_23_2020.ipynb  README.md\n",
            "histogram.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v7SRrc8mH2N",
        "outputId": "6136daad-3456-44d8-858b-c977e084a1fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip'\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/marquesgabi_out_2020/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=Go2BlackWhite.BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "img=ww[0] \n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_k1Ktz3izJv",
        "outputId": "dd95ffc7-f9e1-4243-ce29-cd4657ed9ae5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "# %cd Doutorado\n",
        "Transfere='FotosTreino882_and_Segm.zip'\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()\n",
        "\n",
        "\"\"\"# First step: get the segmented file (photos stored in csv file)\"\"\"\n",
        "\n",
        "labels = [] #name files\n",
        "\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "\n",
        "Num=len(labels)\n",
        "df=pd.read_csv(labels[0])\n",
        "for i in range(1,Num):\n",
        "  df_new=pd.read_csv(labels[i])\n",
        "  df_new = df_new[~df_new['Type'].isin(['G'])] # drop grain row which is not in 882\n",
        "  frames = [df, df_new]\n",
        "  df= pd.concat(frames, ignore_index=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHgqAnaFyCjp",
        "outputId": "8bc38860-ed10-4db9-c9c1-cc5b2023d0b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_set_2020\n",
        "%cd marquesgabi_set_2020"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_set_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/marquesgabi_out_2020/Doutorado/marquesgabi_set_2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from big_segment import Segmenta  # got image provided segmented\n",
        "from ANN_FIND_GRAIN import AnnGrain  # got image provided segmented\n",
        "from psd_mahotas import Mahotas"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPoCxCp4kuRm",
        "outputId": "adc87995-d65f-4f5c-9094-dd6adbfa5370",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "Transfere='FotosTreino882_and_Segm.zip'\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()\n",
        "\n",
        "\"\"\"# First step: get the segmented file (photos stored in csv file)\"\"\"\n",
        "\n",
        "labels = [] #name files\n",
        "\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "\n",
        "Num=len(labels)\n",
        "ANN_dat=pd.read_csv(labels[0])\n",
        "for i in range(1,Num):\n",
        "  df_new=pd.read_csv(labels[i])\n",
        "  df_new = df_new[~df_new['Type'].isin(['G'])] # drop grain row which is not in 882\n",
        "  frames = [ANN_dat, df_new]\n",
        "  ANN_dat= pd.concat(frames, ignore_index=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/marquesgabi_out_2020/Doutorado/marquesgabi_set_2020/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTtH3KDP863"
      },
      "source": [
        "df=Segmenta(img)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nm-Uwb9qwBK",
        "outputId": "f73c5a23-d8b2-4eac-c110-22e986e7d5e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Width           0           1  ...         781         782         783\n",
            "0     118   68.715027   63.545822  ...   92.831085   98.288986   98.113182\n",
            "1     115   41.183437   43.316063  ...  109.278625  113.621239  111.377609\n",
            "2     186  180.092392  112.913521  ...    0.000000    0.000000    0.000000\n",
            "3     130   91.516930   93.883316  ...    7.411834    7.366155    7.474083\n",
            "4     169   56.335209   56.850037  ...    5.678267    7.616435    8.377192\n",
            "..    ...         ...         ...  ...         ...         ...         ...\n",
            "45    182   71.846161   70.130180  ...   86.568054   88.828407   90.532547\n",
            "46    123   80.960411   86.152954  ...   86.764824   87.506645   86.008598\n",
            "47    138   87.697968   63.137573  ...   48.356857   46.882797   45.749840\n",
            "48    123  100.201080  101.029030  ...    8.796022    9.377686    9.990946\n",
            "49    148  114.582916  118.914543  ...   91.555161   91.869255   99.131485\n",
            "\n",
            "[150 rows x 785 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NisVTw0QfAqC",
        "outputId": "ac4400b1-944b-45ff-e71b-9865dd4a6f8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred,confusion_matrix,METRICS=AnnGrain(ANN_dat,df.drop('Width',axis=1)) \n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 11.7437 - accuracy: 0.4519 \n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.7139 - accuracy: 0.4956\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.2290 - accuracy: 0.4956\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7082 - accuracy: 0.5889\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.0537 - accuracy: 0.5015\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8315 - accuracy: 0.5248\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.2281 - accuracy: 0.5656\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.7915 - accuracy: 0.4956\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8722 - accuracy: 0.5394\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.6472\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8423 - accuracy: 0.6676\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.9531 - accuracy: 0.4956\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.1991 - accuracy: 0.5248\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.9038\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.2748 - accuracy: 0.5102\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.4329 - accuracy: 0.5131\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.7201\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9767\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.9971\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.8571\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1599 - accuracy: 0.9796\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.7697\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.8950\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.9184\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7375 - accuracy: 0.6006\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.8513\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.9685 - accuracy: 0.7172\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 2.6293 - accuracy: 0.4956\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.7790 - accuracy: 0.5219\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7697\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9592\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7085\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2276 - accuracy: 0.8980\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.9971\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0914 - accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.9417\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.6822\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2003 - accuracy: 0.9242\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9825\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.7580\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9563\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9942\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.9730 - accuracy: 0.6268\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.3017 - accuracy: 0.5685\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8455\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2017 - accuracy: 0.9942\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.0994 - accuracy: 0.5918\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 3.8931 - accuracy: 0.4956\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 2.8461 - accuracy: 0.5073\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.1609 - accuracy: 0.6006\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1390 - accuracy: 0.9504\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1149 - accuracy: 0.9971\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9971\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9971\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0792 - accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9971\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.8717\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9184\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.7726\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.2378 - accuracy: 0.5977\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.7872\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9971\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9854\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9213\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.9942\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2651 - accuracy: 0.8980\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.5179 - accuracy: 0.5364\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.3745 - accuracy: 0.6181\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.9708\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9883\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.8571\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0954 - accuracy: 0.9650\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9971\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.8746\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0898 - accuracy: 0.9883\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 0.9971\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.9913\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8863\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.5856 - accuracy: 0.5423\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.1185 - accuracy: 0.6531\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.8397\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.2935 - accuracy: 0.5685\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.1756 - accuracy: 0.6501\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 0.9475\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.9650\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.2915 - accuracy: 0.6152\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8859 - accuracy: 0.6647\n",
            "Predicted   0   1\n",
            "Actual           \n",
            "0          51  21\n",
            "1           0  75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuIlULfFx-lF",
        "outputId": "7942e6c6-4fe0-42c3-b6e9-6d6a38f071e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred,confusion_matrix,METRICS=AnnGrain(ANN_dat,df.drop('Width',axis=1)) \n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_1_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_1_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 11.5516 - accuracy: 0.4898\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 3.7005 - accuracy: 0.4956\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.5944 - accuracy: 0.5102\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.0540 - accuracy: 0.5190\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.1792 - accuracy: 0.4956\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7085\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.6618\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.9612 - accuracy: 0.4985\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7464\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8513\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.6618\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7489 - accuracy: 0.5452\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7813\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.5802\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.9184\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.8892\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2911 - accuracy: 0.8950\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.4593 - accuracy: 0.4985\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.0809 - accuracy: 0.5219\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8863\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.6745 - accuracy: 0.5335\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.1147 - accuracy: 0.4956\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.0084 - accuracy: 0.5598\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9359\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9971\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1158 - accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.8047\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8188 - accuracy: 0.5831\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2882 - accuracy: 0.8571\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7774 - accuracy: 0.8105\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.6624 - accuracy: 0.4956\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 2.2722 - accuracy: 0.4956\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.8707 - accuracy: 0.6181\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.9854\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8163\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.6647\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9388\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.9971\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9388\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.9242\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.9971\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1419 - accuracy: 0.9971\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2367 - accuracy: 0.8950\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.8805\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9971\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9534\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9504\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.9745 - accuracy: 0.6735\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.8290 - accuracy: 0.5306\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.8697 - accuracy: 0.6356\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9534\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9971\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.7988\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.8776\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0744 - accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9825\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.7872\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1125 - accuracy: 0.9942\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.9504\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7213 - accuracy: 0.6297\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.8717\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0990 - accuracy: 0.9971\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9621\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2308 - accuracy: 0.8980\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.9971\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9621\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.6735\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8367\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9971\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9942\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.8863\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 0.9738\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9971\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9883\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9971\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.9971\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8447 - accuracy: 0.7114\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.4299 - accuracy: 0.5831\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8397\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 0.9971\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.8805\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.8950\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.9971\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9913\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9971\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9942\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.7872\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.8980\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9942\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8163\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1146 - accuracy: 0.9563\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Predicted   0   1\n",
            "Actual           \n",
            "0          72   0\n",
            "1           4  71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FWWKD60grG_",
        "outputId": "56ee1af1-34b0-4819-81ed-8c7a304e3041",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(confusion_matrix)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted   0   1\n",
            "Actual           \n",
            "0          72   0\n",
            "1           4  71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XdZVmRmk9s6",
        "outputId": "86fd758a-898c-458e-e992-f84a25450a5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv01JmHfmz-1"
      },
      "source": [
        "# open file to get df \n",
        "# use df and ANN to get grains and no grains\n",
        "# use grains to obtain psd"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ELNAEunkox",
        "outputId": "443bc1be-79a5-41d7-a735-0080cbef6962",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/marquesgabi_out_2020/Doutorado/marquesgabi_set_2020/Doutorado/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmPJiuSnnxT9",
        "outputId": "14c7f106-db25-409f-eaba-b475f0fcb896",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "k=0\n",
        "for Item in img_name:\n",
        "  print(k,Item)\n",
        "  k=k+1\n",
        "\n",
        "img=ww[21]\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Fotos_Grandes-3cdAmostra/Q6-8-4.jpg\n",
            "1 Fotos_Grandes-3cdAmostra/Q6-5-3.jpg\n",
            "2 Fotos_Grandes-3cdAmostra/Q6-7-4.jpg\n",
            "3 Fotos_Grandes-3cdAmostra/Q6-8-2.jpg\n",
            "4 Fotos_Grandes-3cdAmostra/Q6-3-2.jpg\n",
            "5 Fotos_Grandes-3cdAmostra/Q6-7-2.jpg\n",
            "6 Fotos_Grandes-3cdAmostra/Q6-4-4.jpg\n",
            "7 Fotos_Grandes-3cdAmostra/Q6-9-5.jpg\n",
            "8 Fotos_Grandes-3cdAmostra/Q6-2-5.jpg\n",
            "9 Fotos_Grandes-3cdAmostra/Q6-8-3.jpg\n",
            "10 Fotos_Grandes-3cdAmostra/Q6-9-3.jpg\n",
            "11 Fotos_Grandes-3cdAmostra/Q6-1-2.jpg\n",
            "12 Fotos_Grandes-3cdAmostra/Q6-6-3.jpg\n",
            "13 Fotos_Grandes-3cdAmostra/Q6-3-4.jpg\n",
            "14 Fotos_Grandes-3cdAmostra/Q6-1-4.jpg\n",
            "15 Fotos_Grandes-3cdAmostra/Q6-6-2.jpg\n",
            "16 Fotos_Grandes-3cdAmostra/Q6-4-3.jpg\n",
            "17 Fotos_Grandes-3cdAmostra/Q6-7-3.jpg\n",
            "18 Fotos_Grandes-3cdAmostra/Q6-2-2.jpg\n",
            "19 Fotos_Grandes-3cdAmostra/Q6-9-2.jpg\n",
            "20 Fotos_Grandes-3cdAmostra/Q6-1-5.jpg\n",
            "21 Fotos_Grandes-3cdAmostra/Q6-6-5.jpg\n",
            "22 Fotos_Grandes-3cdAmostra/Q6-2-1.jpg\n",
            "23 Fotos_Grandes-3cdAmostra/Q6-5-2.jpg\n",
            "24 Fotos_Grandes-3cdAmostra/Q6-4-1.jpg\n",
            "25 Fotos_Grandes-3cdAmostra/Q6-3-1.jpg\n",
            "26 Fotos_Grandes-3cdAmostra/Q6-5-4.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg08LdDEsYLd"
      },
      "source": [
        "df=Segmenta(img)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O2xFH1Ishc2",
        "outputId": "435b2800-a2fd-4a18-da89-2adbc8b72de3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred,confusion_matrix,METRICS=AnnGrain(ANN_dat,df.drop('Width',axis=1)) "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_2_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_2_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 12.0789 - accuracy: 0.4548\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.3850 - accuracy: 0.5102\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.2138 - accuracy: 0.5015\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.6738 - accuracy: 0.4956\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.0725 - accuracy: 0.4956\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.0298 - accuracy: 0.5015\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8093 - accuracy: 0.5015\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7114\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.5364\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7813\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.7638\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.6676\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2551 - accuracy: 0.9825\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8455\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.5889\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.9213\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7767 - accuracy: 0.5160\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.6822\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8426\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.6589\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8371 - accuracy: 0.8513\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 4.7128 - accuracy: 0.4956\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 6.2142 - accuracy: 0.4956\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 5.6723 - accuracy: 0.4956\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 4.5310 - accuracy: 0.4956\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.2829 - accuracy: 0.4956\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 2.0408 - accuracy: 0.4985\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.9545 - accuracy: 0.5510\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.8863\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 0.9971\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1910 - accuracy: 0.9971\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1562 - accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1270 - accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0971 - accuracy: 0.9971\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1322 - accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1526 - accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1702 - accuracy: 0.9621\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2794 - accuracy: 0.8659\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1984 - accuracy: 0.9971\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2475 - accuracy: 0.9242\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.6414\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.8076\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1938 - accuracy: 0.9796\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.6560\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7114\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1677 - accuracy: 0.9534\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1278 - accuracy: 0.9971\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9825\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1618 - accuracy: 0.9913\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0915 - accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0501 - accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1621 - accuracy: 0.9971\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1074 - accuracy: 0.9971\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1327 - accuracy: 0.9942\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.1570 - accuracy: 0.9913\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1165 - accuracy: 0.9679\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1.5428 - accuracy: 0.5335\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.4727 - accuracy: 0.5481\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.5749 - accuracy: 0.6880\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0844 - accuracy: 0.9913\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1491 - accuracy: 0.9796\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2920 - accuracy: 0.8280\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1675 - accuracy: 0.9534\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0602 - accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9971\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1343 - accuracy: 0.9883\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9913\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0364 - accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0795 - accuracy: 0.9942\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.8632 - accuracy: 0.6589\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.2085 - accuracy: 0.5743\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7259\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0956 - accuracy: 0.9913\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9971\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7580\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.5676 - accuracy: 0.7026\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2017 - accuracy: 0.9067\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0260 - accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0195 - accuracy: 0.9971\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0944 - accuracy: 0.9971\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1756 - accuracy: 0.9446\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9971\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9971\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1519 - accuracy: 0.9767\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9971\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0121 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9971\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0919 - accuracy: 0.9971\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.1160 - accuracy: 0.9942\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0627 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0335 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0167 - accuracy: 0.9971\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1252 - accuracy: 0.9942\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9971\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.9971\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.9971\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Predicted   0   1\n",
            "Actual           \n",
            "0          72   0\n",
            "1           0  75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S5a4-cashbB"
      },
      "source": [
        "# print(y_pred.ravel())"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o9IdMKmw5ri"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA2XIpGOyipM"
      },
      "source": [
        "Grain=[]; Ind=[]; Size=[]\n",
        "k=0\n",
        "for item in y_pred:\n",
        "  if(item == 0):\n",
        "    Ind.append(k)\n",
        "  k=k+1\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "df_size = df.drop(df.index[Ind])\n",
        "\n",
        "Width=np.array(df_size['Width'])\n",
        "\n",
        "# print(Width)\n",
        "\n",
        "# print(df_size.shape)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06lkGMZo9uKV"
      },
      "source": [
        "# pd.set_option('display.max_rows', None)\n",
        "# print(df_size)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIeDfpxy0yMh"
      },
      "source": [
        "# print(len(y_pred.ravel()))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIqWqspygJtw",
        "outputId": "af5ef7a1-71e5-400e-f4c2-d9a42dedbd72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>108</td>\n",
              "      <td>67.200279</td>\n",
              "      <td>67.061729</td>\n",
              "      <td>67.252396</td>\n",
              "      <td>64.248283</td>\n",
              "      <td>62.964336</td>\n",
              "      <td>67.041153</td>\n",
              "      <td>64.445808</td>\n",
              "      <td>61.603565</td>\n",
              "      <td>60.831276</td>\n",
              "      <td>77.475998</td>\n",
              "      <td>83.973923</td>\n",
              "      <td>85.625504</td>\n",
              "      <td>85.818924</td>\n",
              "      <td>82.451302</td>\n",
              "      <td>82.735252</td>\n",
              "      <td>84.796974</td>\n",
              "      <td>84.917686</td>\n",
              "      <td>83.133057</td>\n",
              "      <td>84.714676</td>\n",
              "      <td>84.123459</td>\n",
              "      <td>84.510284</td>\n",
              "      <td>82.326477</td>\n",
              "      <td>77.305893</td>\n",
              "      <td>57.480110</td>\n",
              "      <td>38.530861</td>\n",
              "      <td>54.737995</td>\n",
              "      <td>56.122082</td>\n",
              "      <td>52.555553</td>\n",
              "      <td>65.853226</td>\n",
              "      <td>64.786011</td>\n",
              "      <td>63.997246</td>\n",
              "      <td>62.083675</td>\n",
              "      <td>63.688610</td>\n",
              "      <td>67.415634</td>\n",
              "      <td>67.444443</td>\n",
              "      <td>65.596703</td>\n",
              "      <td>57.041149</td>\n",
              "      <td>71.192047</td>\n",
              "      <td>79.399170</td>\n",
              "      <td>...</td>\n",
              "      <td>58.624146</td>\n",
              "      <td>101.400543</td>\n",
              "      <td>147.120697</td>\n",
              "      <td>147.135788</td>\n",
              "      <td>153.198883</td>\n",
              "      <td>159.252396</td>\n",
              "      <td>152.562408</td>\n",
              "      <td>97.582993</td>\n",
              "      <td>89.104248</td>\n",
              "      <td>93.031540</td>\n",
              "      <td>92.115219</td>\n",
              "      <td>91.853218</td>\n",
              "      <td>176.032913</td>\n",
              "      <td>220.386810</td>\n",
              "      <td>181.421112</td>\n",
              "      <td>184.550064</td>\n",
              "      <td>203.381348</td>\n",
              "      <td>89.802467</td>\n",
              "      <td>55.168724</td>\n",
              "      <td>95.674896</td>\n",
              "      <td>101.351166</td>\n",
              "      <td>64.648834</td>\n",
              "      <td>53.858711</td>\n",
              "      <td>27.647463</td>\n",
              "      <td>22.628258</td>\n",
              "      <td>61.353905</td>\n",
              "      <td>137.961578</td>\n",
              "      <td>169.751709</td>\n",
              "      <td>199.278442</td>\n",
              "      <td>193.403290</td>\n",
              "      <td>158.899857</td>\n",
              "      <td>157.703705</td>\n",
              "      <td>134.880646</td>\n",
              "      <td>119.611794</td>\n",
              "      <td>109.555550</td>\n",
              "      <td>87.781891</td>\n",
              "      <td>95.914948</td>\n",
              "      <td>96.669403</td>\n",
              "      <td>95.695473</td>\n",
              "      <td>94.751709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>102</td>\n",
              "      <td>75.575943</td>\n",
              "      <td>77.547485</td>\n",
              "      <td>77.867752</td>\n",
              "      <td>76.542107</td>\n",
              "      <td>80.366020</td>\n",
              "      <td>87.123421</td>\n",
              "      <td>90.010002</td>\n",
              "      <td>92.423691</td>\n",
              "      <td>94.898895</td>\n",
              "      <td>99.696289</td>\n",
              "      <td>104.418694</td>\n",
              "      <td>105.585175</td>\n",
              "      <td>108.229149</td>\n",
              "      <td>111.762405</td>\n",
              "      <td>112.788170</td>\n",
              "      <td>114.287590</td>\n",
              "      <td>115.245682</td>\n",
              "      <td>115.851608</td>\n",
              "      <td>113.395622</td>\n",
              "      <td>102.173019</td>\n",
              "      <td>71.356026</td>\n",
              "      <td>66.533264</td>\n",
              "      <td>78.525955</td>\n",
              "      <td>71.533264</td>\n",
              "      <td>104.176857</td>\n",
              "      <td>131.079590</td>\n",
              "      <td>142.650146</td>\n",
              "      <td>137.755875</td>\n",
              "      <td>75.187630</td>\n",
              "      <td>77.337570</td>\n",
              "      <td>77.584023</td>\n",
              "      <td>78.010002</td>\n",
              "      <td>80.398323</td>\n",
              "      <td>83.883125</td>\n",
              "      <td>87.890045</td>\n",
              "      <td>91.009613</td>\n",
              "      <td>93.420998</td>\n",
              "      <td>97.670898</td>\n",
              "      <td>102.263382</td>\n",
              "      <td>...</td>\n",
              "      <td>71.156494</td>\n",
              "      <td>73.773178</td>\n",
              "      <td>74.072289</td>\n",
              "      <td>71.327957</td>\n",
              "      <td>71.390625</td>\n",
              "      <td>74.890808</td>\n",
              "      <td>76.006165</td>\n",
              "      <td>74.742027</td>\n",
              "      <td>72.409081</td>\n",
              "      <td>62.582855</td>\n",
              "      <td>57.967712</td>\n",
              "      <td>55.245682</td>\n",
              "      <td>86.933495</td>\n",
              "      <td>92.485970</td>\n",
              "      <td>92.054993</td>\n",
              "      <td>72.271828</td>\n",
              "      <td>41.339874</td>\n",
              "      <td>45.309113</td>\n",
              "      <td>45.483665</td>\n",
              "      <td>41.862751</td>\n",
              "      <td>42.365631</td>\n",
              "      <td>42.123421</td>\n",
              "      <td>47.335644</td>\n",
              "      <td>49.167248</td>\n",
              "      <td>50.096119</td>\n",
              "      <td>51.883125</td>\n",
              "      <td>57.680901</td>\n",
              "      <td>58.139954</td>\n",
              "      <td>60.086895</td>\n",
              "      <td>62.332954</td>\n",
              "      <td>62.564407</td>\n",
              "      <td>61.402538</td>\n",
              "      <td>60.561714</td>\n",
              "      <td>65.447525</td>\n",
              "      <td>65.461746</td>\n",
              "      <td>61.584778</td>\n",
              "      <td>56.300659</td>\n",
              "      <td>59.500198</td>\n",
              "      <td>57.645531</td>\n",
              "      <td>53.900814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>189</td>\n",
              "      <td>115.384087</td>\n",
              "      <td>119.803848</td>\n",
              "      <td>123.614548</td>\n",
              "      <td>121.559677</td>\n",
              "      <td>113.529488</td>\n",
              "      <td>109.652954</td>\n",
              "      <td>110.909470</td>\n",
              "      <td>113.403290</td>\n",
              "      <td>116.356651</td>\n",
              "      <td>115.135796</td>\n",
              "      <td>114.677658</td>\n",
              "      <td>117.983536</td>\n",
              "      <td>132.949249</td>\n",
              "      <td>151.240051</td>\n",
              "      <td>136.139923</td>\n",
              "      <td>92.855972</td>\n",
              "      <td>86.204391</td>\n",
              "      <td>76.813446</td>\n",
              "      <td>70.164604</td>\n",
              "      <td>64.063110</td>\n",
              "      <td>58.698215</td>\n",
              "      <td>55.650208</td>\n",
              "      <td>54.230457</td>\n",
              "      <td>51.903980</td>\n",
              "      <td>50.418381</td>\n",
              "      <td>51.990398</td>\n",
              "      <td>52.803844</td>\n",
              "      <td>52.507545</td>\n",
              "      <td>124.566528</td>\n",
              "      <td>127.696861</td>\n",
              "      <td>134.574753</td>\n",
              "      <td>137.123459</td>\n",
              "      <td>118.799721</td>\n",
              "      <td>109.814804</td>\n",
              "      <td>110.816193</td>\n",
              "      <td>114.561050</td>\n",
              "      <td>116.732513</td>\n",
              "      <td>115.621399</td>\n",
              "      <td>118.784637</td>\n",
              "      <td>...</td>\n",
              "      <td>98.960220</td>\n",
              "      <td>93.909477</td>\n",
              "      <td>88.834023</td>\n",
              "      <td>87.366249</td>\n",
              "      <td>90.816200</td>\n",
              "      <td>92.893005</td>\n",
              "      <td>91.238686</td>\n",
              "      <td>95.921799</td>\n",
              "      <td>95.211250</td>\n",
              "      <td>55.658440</td>\n",
              "      <td>60.500687</td>\n",
              "      <td>65.650208</td>\n",
              "      <td>124.486969</td>\n",
              "      <td>111.973946</td>\n",
              "      <td>81.825790</td>\n",
              "      <td>81.159119</td>\n",
              "      <td>82.632378</td>\n",
              "      <td>82.407410</td>\n",
              "      <td>84.993149</td>\n",
              "      <td>88.930038</td>\n",
              "      <td>91.170097</td>\n",
              "      <td>91.203018</td>\n",
              "      <td>91.842247</td>\n",
              "      <td>93.087784</td>\n",
              "      <td>91.492455</td>\n",
              "      <td>85.283951</td>\n",
              "      <td>83.611801</td>\n",
              "      <td>89.757195</td>\n",
              "      <td>95.009605</td>\n",
              "      <td>94.002747</td>\n",
              "      <td>94.578873</td>\n",
              "      <td>96.694107</td>\n",
              "      <td>97.046646</td>\n",
              "      <td>98.267494</td>\n",
              "      <td>97.257889</td>\n",
              "      <td>95.493820</td>\n",
              "      <td>82.725647</td>\n",
              "      <td>52.670784</td>\n",
              "      <td>59.112480</td>\n",
              "      <td>59.982166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100</td>\n",
              "      <td>55.044800</td>\n",
              "      <td>56.771202</td>\n",
              "      <td>92.915199</td>\n",
              "      <td>99.921600</td>\n",
              "      <td>101.460800</td>\n",
              "      <td>103.264008</td>\n",
              "      <td>105.827202</td>\n",
              "      <td>106.987206</td>\n",
              "      <td>107.382401</td>\n",
              "      <td>106.944000</td>\n",
              "      <td>107.619202</td>\n",
              "      <td>105.267204</td>\n",
              "      <td>104.407997</td>\n",
              "      <td>103.403198</td>\n",
              "      <td>104.444809</td>\n",
              "      <td>105.487999</td>\n",
              "      <td>106.281601</td>\n",
              "      <td>106.451202</td>\n",
              "      <td>114.647995</td>\n",
              "      <td>131.176010</td>\n",
              "      <td>136.812805</td>\n",
              "      <td>138.355194</td>\n",
              "      <td>139.807983</td>\n",
              "      <td>141.670410</td>\n",
              "      <td>144.908798</td>\n",
              "      <td>152.192001</td>\n",
              "      <td>159.614410</td>\n",
              "      <td>165.107208</td>\n",
              "      <td>55.555199</td>\n",
              "      <td>58.270401</td>\n",
              "      <td>96.956802</td>\n",
              "      <td>99.764801</td>\n",
              "      <td>101.003197</td>\n",
              "      <td>102.185600</td>\n",
              "      <td>102.118401</td>\n",
              "      <td>104.126404</td>\n",
              "      <td>104.697594</td>\n",
              "      <td>105.871994</td>\n",
              "      <td>105.019188</td>\n",
              "      <td>...</td>\n",
              "      <td>66.979202</td>\n",
              "      <td>61.062401</td>\n",
              "      <td>58.615997</td>\n",
              "      <td>56.774399</td>\n",
              "      <td>55.353600</td>\n",
              "      <td>53.711998</td>\n",
              "      <td>48.771198</td>\n",
              "      <td>47.227200</td>\n",
              "      <td>33.564800</td>\n",
              "      <td>43.697598</td>\n",
              "      <td>103.049591</td>\n",
              "      <td>117.417603</td>\n",
              "      <td>70.273598</td>\n",
              "      <td>66.204796</td>\n",
              "      <td>63.737602</td>\n",
              "      <td>63.217602</td>\n",
              "      <td>59.817596</td>\n",
              "      <td>59.134399</td>\n",
              "      <td>72.748802</td>\n",
              "      <td>85.681602</td>\n",
              "      <td>92.918404</td>\n",
              "      <td>101.020798</td>\n",
              "      <td>109.374405</td>\n",
              "      <td>109.041595</td>\n",
              "      <td>102.398399</td>\n",
              "      <td>87.367996</td>\n",
              "      <td>74.833595</td>\n",
              "      <td>68.540802</td>\n",
              "      <td>67.627205</td>\n",
              "      <td>67.201599</td>\n",
              "      <td>66.783997</td>\n",
              "      <td>64.409599</td>\n",
              "      <td>62.996803</td>\n",
              "      <td>63.521599</td>\n",
              "      <td>59.267197</td>\n",
              "      <td>52.062401</td>\n",
              "      <td>35.966400</td>\n",
              "      <td>44.952000</td>\n",
              "      <td>89.119995</td>\n",
              "      <td>99.235199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>180</td>\n",
              "      <td>83.203949</td>\n",
              "      <td>94.643951</td>\n",
              "      <td>100.599518</td>\n",
              "      <td>103.418282</td>\n",
              "      <td>109.206924</td>\n",
              "      <td>114.899261</td>\n",
              "      <td>119.971367</td>\n",
              "      <td>121.688400</td>\n",
              "      <td>117.168404</td>\n",
              "      <td>105.356560</td>\n",
              "      <td>39.952099</td>\n",
              "      <td>43.460743</td>\n",
              "      <td>45.696793</td>\n",
              "      <td>67.972351</td>\n",
              "      <td>112.264214</td>\n",
              "      <td>135.491364</td>\n",
              "      <td>145.969406</td>\n",
              "      <td>164.432114</td>\n",
              "      <td>166.639511</td>\n",
              "      <td>141.278534</td>\n",
              "      <td>103.257294</td>\n",
              "      <td>106.164459</td>\n",
              "      <td>112.042473</td>\n",
              "      <td>117.602974</td>\n",
              "      <td>117.429634</td>\n",
              "      <td>113.692360</td>\n",
              "      <td>112.992096</td>\n",
              "      <td>119.030128</td>\n",
              "      <td>83.481491</td>\n",
              "      <td>91.380745</td>\n",
              "      <td>97.665192</td>\n",
              "      <td>103.407921</td>\n",
              "      <td>108.929886</td>\n",
              "      <td>114.656303</td>\n",
              "      <td>119.732857</td>\n",
              "      <td>120.470627</td>\n",
              "      <td>112.517052</td>\n",
              "      <td>91.924934</td>\n",
              "      <td>31.202967</td>\n",
              "      <td>...</td>\n",
              "      <td>100.544701</td>\n",
              "      <td>96.363464</td>\n",
              "      <td>93.435066</td>\n",
              "      <td>94.052849</td>\n",
              "      <td>98.437050</td>\n",
              "      <td>107.021240</td>\n",
              "      <td>109.367416</td>\n",
              "      <td>105.526428</td>\n",
              "      <td>105.553101</td>\n",
              "      <td>109.333344</td>\n",
              "      <td>113.573341</td>\n",
              "      <td>123.559013</td>\n",
              "      <td>128.649384</td>\n",
              "      <td>128.777283</td>\n",
              "      <td>126.619759</td>\n",
              "      <td>120.475067</td>\n",
              "      <td>118.223724</td>\n",
              "      <td>126.011856</td>\n",
              "      <td>133.160004</td>\n",
              "      <td>148.506683</td>\n",
              "      <td>148.466187</td>\n",
              "      <td>114.328888</td>\n",
              "      <td>50.679012</td>\n",
              "      <td>56.880997</td>\n",
              "      <td>57.102722</td>\n",
              "      <td>62.943710</td>\n",
              "      <td>74.837044</td>\n",
              "      <td>100.302727</td>\n",
              "      <td>99.405441</td>\n",
              "      <td>102.233093</td>\n",
              "      <td>104.851868</td>\n",
              "      <td>102.318031</td>\n",
              "      <td>98.754089</td>\n",
              "      <td>115.007423</td>\n",
              "      <td>113.781731</td>\n",
              "      <td>110.592102</td>\n",
              "      <td>110.521980</td>\n",
              "      <td>110.414330</td>\n",
              "      <td>110.090881</td>\n",
              "      <td>115.288887</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Width           0           1  ...         781         782         783\n",
              "0    108   67.200279   67.061729  ...   96.669403   95.695473   94.751709\n",
              "1    102   75.575943   77.547485  ...   59.500198   57.645531   53.900814\n",
              "2    189  115.384087  119.803848  ...   52.670784   59.112480   59.982166\n",
              "3    100   55.044800   56.771202  ...   44.952000   89.119995   99.235199\n",
              "4    180   83.203949   94.643951  ...  110.414330  110.090881  115.288887\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciUjF5tmdqLC",
        "outputId": "03484676-b167-41c4-9903-6afdecc6aad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "Size=28\n",
        "qual_img=7\n",
        "L = Width[qual_img]\n",
        "data=np.array(df_size.drop('Width',axis=1).iloc[qual_img]).reshape(Size,Size)\n",
        "img = Image.fromarray(data.astype('uint8'), mode='L')\n",
        "img=np.float32(img)\n",
        "img28=cv2.resize(img,(Size,Size), interpolation = cv2.INTER_AREA)\n",
        "Foto=np.array(img28).reshape(28,28)\n",
        "plt.imshow(Foto, cmap = \"gray\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1bb2e867f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATQ0lEQVR4nO3dTYyc1ZkF4HPamLYxbWww/sFBE4hggUYyGbXQSDEDo2gixxvIJgqLCAQaZxGkRMpiELMISzSaJMoCRXIGFGcUiBAJwgszE/5kDIuIxvKAwXjMWCBjtbGN8Q82pm33O4v+QA10vadTt6q+Uu55JMvtevuruvXzurrrfPdeRgTM7K/fSNsDMLPBcLObVcLNblYJN7tZJdzsZpW4aJA3tnDhwhgdHe1YHxnJ/+/JkgN1rKqTTOttUmPL6iXHAvljPp/j+3VsqbZfL1NTUx1rR44cSY+97LLLOtbOnDmDqampOQdX1OwkNwD4JYAFAP4jIh7Mvn90dBTr1q1L65nshaeOvfTSS9P6woUL0/qFCxe6GhcALFiwIK2rF446Phu7ul/qukub/aKLOr/ESh8XJTtevV4uueSStK4eVzX2AwcOdKw99NBD6bE333xzx9qOHTs61rr+MZ7kAgAPAfg2gBsA3EHyhm6vz8z6q+R39psAvB0R+yNiCsDvAdzWm2GZWa+VNPtaALN/FnmvuexzSG4iOUFy4ty5cwU3Z2Yl+v5pfERsjojxiBhXv+eYWf+UNPtBAFfP+vdXmsvMbAiVNPsrAK4jeQ3JiwF8D8DW3gzLzHqt6+gtIs6TvBfAf2MmenskIt7IjiGZ5pcq28zisyy3BICTJ0+m9SVLlqT1sbGxtJ45f/58Wp+eni6qZ/GYis5Ko7WSnF493+pxU2PP4jU17ixqnc/xamwHD3b+IXjDhg3psVmcmY2rKGePiG0AtpVch5kNhk+XNauEm92sEm52s0q42c0q4WY3q4Sb3awSA53PrixatCitZxniypUr02PVFNezZ8+m9U8++aRjTU3VzHJRQOfoJUpzcnXf1Niz61dZtHo9XHzxxWm9hMrZlez1AuTnEJRMx07PY0mv1cz+arjZzSrhZjerhJvdrBJudrNKuNnNKjFU0ZuKUtau/dKqV5+56qqr0mOXL1+e1tUqOtkU2T179qTHqlivdAWf7HgVX6lYUMVjJRGVut/q9aDGXjK20pVtT58+ndazKdUl9zsbt9/ZzSrhZjerhJvdrBJudrNKuNnNKuFmN6uEm92sEgPN2SMinRK5evXq9PgsZ8+2sQX0tMErr7wyrWdZudrxc2JiIq2raaRKlqWXZtVqOWeVR2fPt5oeq5aaVrLHVd22ek7U2NT1Z8+Lek6yjN5TXM3MzW5WCze7WSXc7GaVcLObVcLNblYJN7tZJQaas4+OjuLaa6/tWFdz0rN8sXT+scpVs4xfZfTqHIBnn302ras56ZnSLZtLzwFQ119yrDoHIMuc1fkH6n6rufJqbBmV0Wdz5bNji5qd5DsATgG4AOB8RIyXXJ+Z9U8v3tn/MSKO9uB6zKyP/Du7WSVKmz0A/InkqyQ3zfUNJDeRnCA5obbEMbP+Kf0xfn1EHCS5EsAzJN+KiBdnf0NEbAawGQCuuOKK7j+tMbMiRe/sEXGw+fswgCcB3NSLQZlZ73Xd7CSXkBz79GsA3wKwu1cDM7PeKvkxfhWAJ5t8+yIAj0bEf2UHLFq0CNdff31az5Rk6aWZbZbLqvnsy5YtS+vHjx9P62+99VZaV/OfM6WPSz/npKvbVmMvmTOuqLFNTU2l9ZLzD7rd4rvrexwR+wGs6/Z4MxssR29mlXCzm1XCzW5WCTe7WSXc7GaVGOgU15GRkTSmUpFCNq1Qbf+rYruSJZEXL16cHptNzQWAjRs3pvUjR46k9Q8//LBjTUVf6n6XTgXN9HMKq3Lu3Lm0rh4XFZeq13IW/alYMHu9Zc+H39nNKuFmN6uEm92sEm52s0q42c0q4WY3q4Sb3awSA83ZgTwHHB0dTY/N8seSY4GyJZfVdtBqiqs6R2D9+vVp/dFHH+1YUxm/ypNLp4KWHK+e09LlwzNqCbVsOWdA5+xLly7tWFNTprPHxTm7mbnZzWrhZjerhJvdrBJudrNKuNnNKuFmN6vEQHN2kmnuqjLhdDtakeeqeddq7vSJEyc61tSWzGpsqr5uXb6I7969ezvWXnrppaLbVnP11fLf2fFqrnyp7DlXz/fHH3+c1tWWzepxGRsb6/rY7H5l5x74nd2sEm52s0q42c0q4WY3q4Sb3awSbnazSrjZzSox8PnsGTWHOMts1ZxwlYuqerbOeJbBA8CZM2fSupoPr+ba33XXXR1ramzbtm1L6ypnV3Ovs3Mn1HkV6rpVHp2dQ6BydjVfXT0nJXPSS+bxF+XsJB8heZjk7lmXXU7yGZL7mr+Xq+sxs3bN58f43wDY8IXL7gPwXERcB+C55t9mNsRks0fEiwCOfeHi2wBsab7eAuD2Ho/LzHqs2w/oVkXEZPP1IQCrOn0jyU0kJ0hOfPTRR13enJmVKv40PmY+qej4aUVEbI6I8YgYVx9EmVn/dNvs75NcAwDN34d7NyQz64dum30rgDubr+8E8FRvhmNm/SJzdpKPAbgVwAqS7wH4KYAHATxO8h4A7wL47nxuLCLSfLNkzrnab1s5efJkWs+yT3XbKjdVebNadz7LVu++++702AMHDqT1l19+Oa2vXr06rWfnGOzfv7/rYwHg7NmzaT2jMvprrrkmra9cubLo+rNzANQ5I1nGn70WZLNHxB0dSt9Ux5rZ8PDpsmaVcLObVcLNblYJN7tZJdzsZpUY6BTX6elpZKfMqmmmU1NTHWsq/ipZnhdAOm61HLM6c1DdtppOmT1u6rpvueWWtP7444+ndRW9lSz/nT3fgI7esqj22LEvTvf4PLXMtYreVHyWxbEjI/l7cLdbVfud3awSbnazSrjZzSrhZjerhJvdrBJudrNKuNnNKjHwpaSzzFhtk5sta6ymkaqsWuWq2dhUXqyWLVbLdam8Obt9lbOr5btLlthWx2cZPKDPT1CPS4njx4+n9dJtuLtdDhrQr+VO/M5uVgk3u1kl3OxmlXCzm1XCzW5WCTe7WSXc7GaVGHjOnmWIKj/Msm6VyarcU+XF2bhVTt5mZqvmfG/fvj2tq3nbKqcv2TZZ5ejq+CzjV+sblG4Xrc5vyMam+iA7PyE71u/sZpVws5tVws1uVgk3u1kl3OxmlXCzm1XCzW5WiYHm7CMjI+mc9JL57CXb985HlpuqHFzN21ZZtaqfPn26Y23Hjh3psbt3707r6vwFtT569pyW5uwl1G2rbbLV+gclewGo5zsbe/Zak+/sJB8heZjk7lmXPUDyIMldzZ+N6nrMrF3z+TH+NwA2zHH5LyLixubPtt4Oy8x6TTZ7RLwIIN8rx8yGXskHdPeSfK35MX95p28iuYnkBMmJ7HdLM+uvbpv9VwC+BuBGAJMAftbpGyNic0SMR8T4kiVLurw5MyvVVbNHxPsRcSEipgH8GsBNvR2WmfVaV81Ocs2sf34HQJ7fmFnrZM5O8jEAtwJYQfI9AD8FcCvJGwEEgHcA/GC+N5jtPa1+zM/ybJVll2a22W2ruc3q/AFFnUOwb9++jrWtW7cW3XbJevpA95kwUD6fPZvnr9bDX76848dQAPQ+BSVrv6v71S3Z7BFxxxwXP9yHsZhZH/l0WbNKuNnNKuFmN6uEm92sEm52s0oMfCnpjJoumcUdZ86cSY9VdTVNNYtqVDx14sSJtH7y5Mm0fujQobT+xBNPdKypGEfV1X0roaI3NTZ1fBbzquhNxalqueeS+EyNTb1WO/E7u1kl3OxmlXCzm1XCzW5WCTe7WSXc7GaVcLObVWKotmxWOXumdFlilZtmSwOr7Z7Vls1qua6nn346rR89erRjTWWyamtilWWr68+eF7XVtXpOS7Y2VrKMHtDLPaulpLPXjDo2OwcgG7ff2c0q4WY3q4Sb3awSbnazSrjZzSrhZjerhJvdrBIDzdkjomhZ5SzTVderlvZVslxV5ewqk33++efT+oEDB9J6lkerLZdVnqyyarXMdVZX5z6oed0l50ao+6Xqamwl902tIZC93rLHxO/sZpVws5tVws1uVgk3u1kl3OxmlXCzm1XCzW5WiYHm7NPT02nmrLLwrK7mAJfMuwbyvFhlzdu3b0/ral14JbtvKkdX6+m3mbOrHF2tf5A9Lur1ULouvFp3PlN6Tkgn8p2d5NUkXyD5Jsk3SP6oufxyks+Q3Nf8nW9obWatms+P8ecB/CQibgDw9wB+SPIGAPcBeC4irgPwXPNvMxtSstkjYjIidjZfnwKwB8BaALcB2NJ82xYAt/drkGZW7i/6gI7kVwF8HcCfAayKiMmmdAjAqg7HbCI5QXJC/X5oZv0z72YneSmAPwD4cUR8bifCmPk0Y85PNCJic0SMR8S4WtzQzPpnXs1OciFmGv13EfHH5uL3Sa5p6msAHO7PEM2sF2T0xpkc4GEAeyLi57NKWwHcCeDB5u+n1HVNT0/L5YMzWZyhphyqqERNkc2Wg37hhRfSY48dO5bW1U88K1asSOtZjKSisdJtk1V8ltVVLKjq6nHLXi8qGiuNv0qW4Fb3O4uZs3HPJ2f/BoDvA3id5K7msvsx0+SPk7wHwLsAvjuP6zKzlshmj4iXAHT67+KbvR2OmfWLT5c1q4Sb3awSbnazSrjZzSrhZjerxECnuJ4/fz7NnNWSy9myyCoXVcs9q2mmO3fu7FhT5w6Mjo6mdZX5qumYarnojDoHoHTb5CwzLr3fKmfP6mq55tLzD9R5HypL7we/s5tVws1uVgk3u1kl3OxmlXCzm1XCzW5WCTe7WSUGvmVzlnefOnUqPT6bU57VAOD06dNpfXJyMq1n88JVxq+WPFZUjp/V1VJgaj66yptVXr148eKONZWjq+tW9SzLVjm3ek7V0uXq/INMyXbR3rLZzNzsZrVws5tVws1uVgk3u1kl3OxmlXCzm1VioDk7kOeAKhM+cuRIx5rK2dX8Y5W7ZpmuyqpL5y6r+5atA6DWCChZe720rnL2Utnjrl4Pql66rnzJOQDZ2Jyzm5mb3awWbnazSrjZzSrhZjerhJvdrBJudrNKzGd/9qsB/BbAKgABYHNE/JLkAwD+GcCn4ff9EbEtu66ISDPCo0ePpmPJ8ubSedcq883OASjZixsoz3SzNQJUDr506dK0Xvq4ZdR5FSXz1dXx/V73vSQrV+dGZGPLXovzeabOA/hJROwkOQbgVZLPNLVfRMS/z+M6zKxl89mffRLAZPP1KZJ7AKzt98DMrLf+ot/ZSX4VwNcB/Lm56F6Sr5F8hOTyDsdsIjlBckL9eGJm/TPvZid5KYA/APhxRJwE8CsAXwNwI2be+X8213ERsTkixiNiXO15Zmb9M69mJ7kQM43+u4j4IwBExPsRcSEipgH8GsBN/RummZWSzc6Zj4IfBrAnIn4+6/I1s77tOwB29354ZtYr8/k0/hsAvg/gdZK7msvuB3AHyRsxE8e9A+AH6orOnj2LvXv3pvVMFiuoqEPFY2qaaqZ0+9/S7YGXLVvWsaait9JoTY2t5DlT161k903dttriu3TacvZaV59tZc9JNsV1Pp/GvwRgrqA3zdTNbLj4DDqzSrjZzSrhZjerhJvdrBJudrNKuNnNKjHQpaSnp6fT7YVVppvVS3N2dXx22yrLHhsbS+vq+JL7prZ7/uCDD9J66TTU7HErfU5UPTt3Qr3W+j2PI9vGW01pzupZze/sZpVws5tVws1uVgk3u1kl3OxmlXCzm1XCzW5WCWbzX3t+Y+QRAO/OumgFgHz96PYM69iGdVyAx9atXo7tbyLiyrkKA232L904ORER460NIDGsYxvWcQEeW7cGNTb/GG9WCTe7WSXabvbNLd9+ZljHNqzjAjy2bg1kbK3+zm5mg9P2O7uZDYib3awSrTQ7yQ0k95J8m+R9bYyhE5LvkHyd5C6SEy2P5RGSh0nunnXZ5SSfIbmv+XvOPfZaGtsDJA82j90ukhtbGtvVJF8g+SbJN0j+qLm81ccuGddAHreB/85OcgGA/wXwTwDeA/AKgDsi4s2BDqQDku8AGI+I1k/AIPkPAD4C8NuI+Nvmsn8DcCwiHmz+o1weEf8yJGN7AMBHbW/j3exWtGb2NuMAbgdwF1p87JJxfRcDeNzaeGe/CcDbEbE/IqYA/B7AbS2MY+hFxIsAjn3h4tsAbGm+3oKZF8vAdRjbUIiIyYjY2Xx9CsCn24y3+tgl4xqINpp9LYADs/79HoZrv/cA8CeSr5Lc1PZg5rAqIiabrw8BWNXmYOYgt/EepC9sMz40j10325+X8gd0X7Y+Iv4OwLcB/LD5cXUoxczvYMOUnc5rG+9BmWOb8c+0+dh1u/15qTaa/SCAq2f9+yvNZUMhIg42fx8G8CSGbyvq9z/dQbf5+3DL4/nMMG3jPdc24xiCx67N7c/baPZXAFxH8hqSFwP4HoCtLYzjS0guaT44AcklAL6F4duKeiuAO5uv7wTwVItj+Zxh2ca70zbjaPmxa33784gY+B8AGzHzifz/AfjXNsbQYVzXAvif5s8bbY8NwGOY+bHuHGY+27gHwBUAngOwD8CzAC4forH9J4DXAbyGmcZa09LY1mPmR/TXAOxq/mxs+7FLxjWQx82ny5pVwh/QmVXCzW5WCTe7WSXc7GaVcLObVcLNblYJN7tZJf4f9A6M0pynRx8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTwwISIWiYRi",
        "outputId": "3be58e89-0b5e-4554-8c9c-a5e294d3dc22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "'''\n",
        "it is not change the size? why? ????\n",
        "\n",
        "size = 20\n",
        "img1200=cv2.resize(img28,(Size,Size), interpolation = cv2.INTER_AREA)\n",
        "plt.imshow(img1200, cmap = \"gray\")\n",
        "'''"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nit is not change the size? why? ????\\n\\nsize = 20\\nimg1200=cv2.resize(img28,(Size,Size), interpolation = cv2.INTER_AREA)\\nplt.imshow(img1200, cmap = \"gray\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6UQexMtkz5t"
      },
      "source": [
        "df_getBetter = GetBetter(img)\n",
        "#df_getBetter = GetBetter(data)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJgilCmz7I9A",
        "outputId": "b22eefc9-5ca7-4289-b971-b34d3cb57c6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "qual_img =49\n",
        "data=np.array(df_getBetter.drop('Width',axis=1).iloc[qual_img]).reshape(Size,Size)\n",
        "img = Image.fromarray(data.astype('uint8'), mode='L')\n",
        "img=np.float32(img)\n",
        "img28=cv2.resize(img,(Size,Size), interpolation = cv2.INTER_AREA)\n",
        "plt.imshow(img28, cmap = \"gray\")\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1bb45dd128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DXbVnD5HaeO",
        "outputId": "396b6a67-0452-4d7a-bcbd-324a082b1878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.imshow(Foto, cmap = \"gray\")\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1bb4ae2cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucryOhXfHcS1",
        "outputId": "a03d895d-29a8-4050-a964-16491e0fb2b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.imshow(img28, cmap = \"gray\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1bb47603c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-MTA4fXg2W0"
      },
      "source": [
        "mean_value = np.mean(img)\n",
        "img_new = img.copy()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbcfWPMdewq3",
        "outputId": "ff1154df-c6ce-4600-ef88-3957f0868a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "\n",
        "for i in range(28):\n",
        "  for j in range(28):\n",
        "    if img[i,j] < mean_value:\n",
        "      img_new[i,j] = 255\n",
        "    else:\n",
        "      img_new[i,j] = 0\n",
        "\n",
        "img28=cv2.resize(img_new,(Size,Size), interpolation = cv2.INTER_AREA)\n",
        "Foto=np.array(img28).reshape(28,28)\n",
        "plt.imshow(Foto, cmap = \"gray\")\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1bb712fc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spRNBSwifDqQ",
        "outputId": "2646ad79-01b1-4c24-b9e9-7f9206d4b791",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "L = Width[qual_img]\n",
        "Area = np.sum(img_new) / (255.0 * 28 * 28)* L*L\n",
        "print(Area)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26527.48979591837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GP_DXsWibOX"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(df_size) \n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ydbrnjewBYL",
        "outputId": "12724b90-2ebd-44a2-87e9-04b46ac51b11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_size.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(147, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L3IfgxMs3dI",
        "outputId": "6cf1f2b7-635c-4d3d-8df6-7f08eb5d6a86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# print(Area_All)\n",
        "print(Diameter_All)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0441322772859976, 0.9202365101633908, 1.6721913704263902, 1.0091645625401795, 1.6220030993802572, 1.765989965090816, 0.8668816105460294, 1.1637969047101393, 1.372463805054644, 1.737421684400083, 1.3935352537567816, 1.367379621730681, 1.1109925413000319, 1.5920838330870288, 1.2400215621802124, 1.4367646348892205, 1.5864748566771294, 0.899853203855231, 1.1166884589142698, 1.1158313264709305, 1.5109592659467708, 1.5001782779597426, 1.3995576624051358, 1.4491961830717957, 1.7017274133581486, 1.6487983502557528, 1.5636956450232589, 1.8137928043584128, 1.51845410492594, 1.44971656320321, 1.011669892340984, 1.3690681030956704, 1.7959967910843628, 1.5746350979055572, 1.0617088066199303, 1.1556426611527861, 1.3935012978057109, 1.1698821966172528, 1.1989133965225887, 1.42973700322195, 1.1875264345512841, 1.33885418808784, 1.4826902255635035, 0.9370990613957646, 1.66259515073088, 1.2895326039003663, 1.2008281577069195, 1.687100268632883, 1.9085383560835356, 1.5087771208906144, 1.743329313976627, 1.245206654951052, 1.2222254429510049, 1.919898069274005, 1.327452898443774, 1.0974531376752565, 1.3560542514148277, 1.4653763837250726, 1.612904867040065, 1.3276492296951377, 1.1973899211078929, 1.6420660579059305, 1.0996151678685746, 1.211812122326398, 1.2293817896303887, 1.6793443898792804, 1.2690533086728804, 1.0440399582689324, 0.8472720122387273, 0.9617474878536724, 0.9672273240832585, 1.6742865500851998, 1.5560093869228877, 1.493910834596196, 1.3835559997114966, 1.402137323224416, 1.6071793684662274, 1.3032243572013078, 1.412462067529009, 1.1818972591940307, 1.4298211702183257, 1.351505296070165, 1.2639337686393033, 1.7793228274892103, 0.8299070906329501, 1.8399938876497541, 1.038356503245639, 1.8054699934060723, 1.3384496535392945, 1.690594340766354, 1.5905811765422146, 1.2660878118765626, 1.7281165549014645, 1.5281816252797664, 1.7040718012956009, 1.374609624323125, 1.6517777167280763, 1.4366716580382792, 1.681902281424718, 1.1475205808031144, 1.6236505213059425, 1.5790579649640977, 1.2133995767881376, 1.9397743444592326, 1.8499982490645497, 1.0507579307644535, 1.8204094512375995, 1.7188568935099755, 0.9993875430381912, 1.1438609333013918, 1.9086588479108024, 1.5691865692961484, 0.9343843288967228, 1.2232194360898903, 1.2508913794942809, 1.20856763960373, 1.0140753305336476, 1.6408676696663713, 1.5431461008076135, 1.8213137466583862, 1.463282627353566, 1.625791129382912, 1.9537155789256817, 1.8525965879758728, 1.7059445810535374, 1.7355653676791136, 1.1874760110093416, 0.976306662679409, 0.8624123614022626, 1.452116009407728, 1.3894546146779116, 1.5655766431094706, 0.856804664689888, 1.5901041412240304, 1.0323328442165622, 1.132280118001423, 1.1501845405049247, 1.2677145939462173, 1.7518856674975394, 1.560692362188809, 1.599485367992556, 0.9378944778820983, 1.5949697143905863, 1.4034407766549475, 1.3978695122831037, 1.4936876656218079, 1.6554785641849619]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aecOBA5LNmD",
        "outputId": "d672ced0-7bca-40c6-d4a7-10c0c5964d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "d = 1.6343255246592054\n",
        "r = d / 2.0\n",
        "Area = np.pi * d**2 / 4; print('Area=',Area)\n",
        "'''"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nd = 1.6343255246592054\\nr = d / 2.0\\nArea = np.pi * d**2 / 4; print('Area=',Area)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeLlypq5gbFa"
      },
      "source": [
        ""
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJFWGVQJLwRo",
        "outputId": "7fd82009-db47-4277-ed25-94751e1fcff4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "diam = Diameter_All.copy()\n",
        "PSD_value = PSD(diam)\n",
        "print(PSD_value)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   0   0   0   0   1  13  24 109]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvked-F_kPwi",
        "outputId": "1a0a5ee3-47f8-4e75-abfa-d3bee2c1ddd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "%cd marquesgabi_out_2020\n",
        "PSD_imageJ = 'Areas_ImageJ.csv'\n",
        "df_imageJ = pd.read_csv(PSD_imageJ)\n",
        "print(df_imageJ.head(3))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_out_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/marquesgabi_out_2020/Doutorado/marquesgabi_set_2020/Doutorado/Doutorado/marquesgabi_out_2020\n",
            "  Unnamed: 0 Unnamed: 1        Unnamed: 2\n",
            "0                  Area                 d\n",
            "1          1      2,001  50.4752649569572\n",
            "2          2      0.820  1.02179080270499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnmV_uagvrhZ",
        "outputId": "e5322b62-2499-4d6e-d3e0-798741ec7bb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_imageJ.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiRluM5zxWdy",
        "outputId": "0188e801-b9e5-49a5-ee12-f08dd15cc7f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_imageJ['Unnamed: 1']\n",
        "Area = []; k = 0\n",
        "diam = []\n",
        "for item in df_imageJ['Unnamed: 1']:\n",
        "  if k > 0:\n",
        "    value =item.replace(',','.')\n",
        "    Area.append(float(value))\n",
        "    d = (4*float(value)/np.pi)**0.5\n",
        "    diam.append(d)\n",
        "  k = k +1\n",
        "PSD_new = pd.DataFrame({'Area': Area, 'Diam':diam})\n",
        "print(PSD_new)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Area      Diam\n",
            "0   2.001  1.596168\n",
            "1   0.820  1.021791\n",
            "2   1.270  1.271619\n",
            "3   0.958  1.104429\n",
            "4   1.162  1.216349\n",
            "5   2.014  1.601345\n",
            "6   1.078  1.171560\n",
            "7   1.234  1.253466\n",
            "8   1.262  1.267607\n",
            "9   1.347  1.309601\n",
            "10  1.313  1.292967\n",
            "11  2.449  1.765832\n",
            "12  1.445  1.356404\n",
            "13  1.209  1.240704\n",
            "14  3.564  2.130217\n",
            "15  1.590  1.422832\n",
            "16  0.891  1.065109\n",
            "17  1.329  1.300821\n",
            "18  1.403  1.336546\n",
            "19  0.626  0.892775\n",
            "20  1.650  1.449429\n",
            "21  1.551  1.405274\n",
            "22  2.118  1.642170\n",
            "23  1.194  1.232983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Fdww7M1KSx",
        "outputId": "0fc17293-5b85-4835-fb5d-8a6faa820cc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "PSD_new = PSD(PSD_new['Diam'])\n",
        "print(PSD_new)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  0  0  0  1  4 19]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pq4DTm1np4i"
      },
      "source": [
        ""
      ]
    }
  ]
}