{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_GRAIN_NOT_GRAIN_out_19_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/marquesgabi_out_2020/blob/main/PSD_GRAIN_NOT_GRAIN_out_19_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZEvJvfoibE4",
        "outputId": "7d78ba14-7f4b-461a-df2b-b43ef3b7dac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mahotas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/3b/1f3fe2f86ffdb4a2fbc6baaf4ef0e6cebdd3e127de44ddd188dc2ed0d412/mahotas-1.4.11-cp36-cp36m-manylinux2010_x86_64.whl (5.7MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7MB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mahotas) (1.18.5)\n",
            "Installing collected packages: mahotas\n",
            "Successfully installed mahotas-1.4.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_a6PJ1iUnT"
      },
      "source": [
        "import mahotas.features.texture as mht\n",
        "import mahotas.features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj62HANgnpnR",
        "outputId": "a9067bf8-a99f-4d57-d47d-6430ac01df1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "\n",
        "!git clone https://github.com/ucfilho/marquesgabi_out_2020/\n",
        "%cd marquesgabi_out_2020\n",
        "from Get_PSDArea import PSDArea"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'marquesgabi_out_2020'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 57 (delta 30), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (57/57), done.\n",
            "/content/marquesgabi_out_2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VcTdaNVh9EE",
        "outputId": "ad622aea-0e09-4710-eed9-d81c522e452f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'marquesgabi_fev_2020'...\n",
            "remote: Enumerating objects: 73, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 73 (delta 37), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (73/73), done.\n",
            "/content/marquesgabi_out_2020/marquesgabi_fev_2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v7SRrc8mH2N",
        "outputId": "5f99e29a-687d-428d-8b82-8f2d1da56d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip'\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Doutorado'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 287 (delta 15), reused 0 (delta 0), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (287/287), 78.56 MiB | 38.16 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n",
            "/content/marquesgabi_out_2020/marquesgabi_fev_2020/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=Go2BlackWhite.BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "img=ww[0] \n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_k1Ktz3izJv",
        "outputId": "c950e373-f7b4-4ed9-d7a4-a12ed709ef83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "# %cd Doutorado\n",
        "Transfere='FotosTreino882_and_Segm.zip'\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()\n",
        "\n",
        "\"\"\"# First step: get the segmented file (photos stored in csv file)\"\"\"\n",
        "\n",
        "labels = [] #name files\n",
        "\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "\n",
        "Num=len(labels)\n",
        "df=pd.read_csv(labels[0])\n",
        "for i in range(1,Num):\n",
        "  df_new=pd.read_csv(labels[i])\n",
        "  df_new = df_new[~df_new['Type'].isin(['G'])] # drop grain row which is not in 882\n",
        "  frames = [df, df_new]\n",
        "  df= pd.concat(frames, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Doutorado'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 287 (delta 15), reused 0 (delta 0), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (287/287), 78.56 MiB | 37.21 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHgqAnaFyCjp",
        "outputId": "7f92ad3a-6ba4-401f-fda6-04225443ef03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_set_2020\n",
        "%cd marquesgabi_set_2020"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'marquesgabi_set_2020'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 266 (delta 44), reused 0 (delta 0), pack-reused 194\u001b[K\n",
            "Receiving objects: 100% (266/266), 7.00 MiB | 3.36 MiB/s, done.\n",
            "Resolving deltas: 100% (162/162), done.\n",
            "/content/marquesgabi_out_2020/marquesgabi_fev_2020/Doutorado/marquesgabi_set_2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from big_segment import Segmenta  # got image provided segmented\n",
        "from ANN_FIND_GRAIN import AnnGrain  # got image provided segmented\n",
        "from psd_mahotas import Mahotas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPoCxCp4kuRm",
        "outputId": "96b388d3-1a38-4c06-ef9e-d3a9e1472480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "Transfere='FotosTreino882_and_Segm.zip'\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()\n",
        "\n",
        "\"\"\"# First step: get the segmented file (photos stored in csv file)\"\"\"\n",
        "\n",
        "labels = [] #name files\n",
        "\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "\n",
        "Num=len(labels)\n",
        "ANN_dat=pd.read_csv(labels[0])\n",
        "for i in range(1,Num):\n",
        "  df_new=pd.read_csv(labels[i])\n",
        "  df_new = df_new[~df_new['Type'].isin(['G'])] # drop grain row which is not in 882\n",
        "  frames = [ANN_dat, df_new]\n",
        "  ANN_dat= pd.concat(frames, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Doutorado'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 287 (delta 15), reused 0 (delta 0), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (287/287), 78.56 MiB | 36.53 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n",
            "/content/marquesgabi_out_2020/marquesgabi_fev_2020/Doutorado/marquesgabi_set_2020/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTtH3KDP863"
      },
      "source": [
        "df=Segmenta(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nm-Uwb9qwBK",
        "outputId": "a3b1657d-07bf-4c63-b575-e6cac6e85a8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Width          0          1  ...         781         782         783\n",
            "0     161  28.986769  28.287336  ...   45.272213   42.183365   26.758034\n",
            "1     106  69.403702  71.672119  ...   59.045212   59.579922   57.194023\n",
            "2     113  70.552589  66.295403  ...   56.171585   53.243950   52.019894\n",
            "3     199  95.229507  99.569855  ...   57.668190   49.434433   73.674828\n",
            "4     171  85.597519  92.534492  ...   76.063141   69.080406   71.079170\n",
            "..    ...        ...        ...  ...         ...         ...         ...\n",
            "45    193  59.017559  60.358051  ...    8.875191    7.276142    5.602647\n",
            "46    118  79.752083  85.438950  ...  135.040207  135.631989  136.946564\n",
            "47    186  95.568161  98.351151  ...    5.759857    5.654412    5.584114\n",
            "48    172   2.476474   0.969713  ...   48.823154   30.236885   15.388860\n",
            "49    106  41.782486  41.833752  ...    3.895693    2.441438    0.679245\n",
            "\n",
            "[150 rows x 785 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NisVTw0QfAqC",
        "outputId": "2033dad5-4999-4d12-ed17-7d0c9bd2a666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_pred,confusion_matrix,METRICS=AnnGrain(ANN_dat,df.drop('Width',axis=1)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 33.5237 - accuracy: 0.4169 \n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.5556 - accuracy: 0.4985\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.8800 - accuracy: 0.5160\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 3.7409 - accuracy: 0.4956\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 3.7750 - accuracy: 0.4956\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 3.1000 - accuracy: 0.4956\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.2300 - accuracy: 0.4956\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.2851 - accuracy: 0.4956\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.6531\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.8309\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7521 - accuracy: 0.5277\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.6181\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.9592\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.6035\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.6501\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8455\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9942\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9913\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.9971\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9650\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9971\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7945 - accuracy: 0.6268\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.1335 - accuracy: 0.5190\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7405\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2604 - accuracy: 0.9883\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.6356\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.6560\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.9796\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.7668\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.8580 - accuracy: 0.5773\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3668 - accuracy: 0.7813\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.9942\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8513 - accuracy: 0.6501\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 1.1357 - accuracy: 0.5452\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.7609\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9971\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8047\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.8163\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.9971\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8713 - accuracy: 0.7493\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.2988 - accuracy: 0.5364\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.6735\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1093 - accuracy: 0.9796\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2623 - accuracy: 0.9009\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7237 - accuracy: 0.6122\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.7784\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0950 - accuracy: 0.9971\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9942\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9971\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1470 - accuracy: 0.9854\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.6968\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2421 - accuracy: 0.8834\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9971\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1632 - accuracy: 0.9475\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9796\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9942\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3038 - accuracy: 0.8192\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9475\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.9971\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9708\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 0.9679\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9971\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9971\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2925 - accuracy: 0.8426\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.8484\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9971\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 0.9971\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.8746\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1317 - accuracy: 0.9621\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8746\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.9015 - accuracy: 0.6356\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.9329\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7551\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.1433 - accuracy: 0.6122\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.8834\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0477 - accuracy: 0.9971\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9971\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.7405\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.6822\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0917 - accuracy: 0.9825\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9854\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.9017 - accuracy: 0.6560\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7376\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9971\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9971\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0890 - accuracy: 0.9708\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2016 - accuracy: 0.8980\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9942\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9854\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.2469 - accuracy: 0.6239\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8017\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 0.9971\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8251\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 0.9242\n",
            "Predicted   0   1\n",
            "Actual           \n",
            "0          72   0\n",
            "1           0  75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuIlULfFx-lF",
        "outputId": "5dae937c-0962-46a1-d4ae-13b92caf8aa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_pred,confusion_matrix,METRICS=AnnGrain(ANN_dat,df.drop('Width',axis=1)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_1_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_1_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 17.9967 - accuracy: 0.4723\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.4692 - accuracy: 0.4956\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.3473 - accuracy: 0.5277\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.6710 - accuracy: 0.4956\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.7368 - accuracy: 0.4956\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.6831 - accuracy: 0.4956\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.2346 - accuracy: 0.4956\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.6382 - accuracy: 0.4956\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.0482 - accuracy: 0.4956\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.5831\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.9155\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7181 - accuracy: 0.5219\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.8421 - accuracy: 0.4985\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.5831\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.9417\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8134\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.5685\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.7347\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2021 - accuracy: 0.9913\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8513\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.6268\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8017\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.9446\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.5525 - accuracy: 0.5044\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.2830 - accuracy: 0.4956\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.8120 - accuracy: 0.4956\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.0628 - accuracy: 0.5219\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7114\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1584 - accuracy: 0.9971\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 0.9854\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8251\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2362 - accuracy: 0.9475\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9971\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1103 - accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.9971\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7493\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6968 - accuracy: 0.5889\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.7114\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.9796\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.9942\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7085\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7992 - accuracy: 0.5889\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7085\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.9650\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9971\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9942\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.7988\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.7843\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1726 - accuracy: 0.9767\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9971\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9621\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8280\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9679\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0519 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 0.9971\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9971\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0413 - accuracy: 0.9971\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9942\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9679\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9971\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9883\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.9942\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2836 - accuracy: 0.9155\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.1792 - accuracy: 0.5102\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.2506 - accuracy: 0.5102\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.2259 - accuracy: 0.5860\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8397\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9971\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9971\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.2575 - accuracy: 0.8630\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2193 - accuracy: 0.9009\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9913\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9009\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9854\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0554 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9971\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9942\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9067\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9971\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0346 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9971\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.9942\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9913\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9971\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9796\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9971\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9971\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9883\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 1.0000\n",
            "Predicted   0   1\n",
            "Actual           \n",
            "0          72   0\n",
            "1           0  75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FWWKD60grG_",
        "outputId": "c721f164-dbae-48da-a3c5-62be86c649f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted   0   1\n",
            "Actual           \n",
            "0          72   0\n",
            "1           0  75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XdZVmRmk9s6",
        "outputId": "de211894-fb50-4905-9e11-9dc0dbb4cf54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv01JmHfmz-1"
      },
      "source": [
        "# open file to get df \n",
        "# use df and ANN to get grains and no grains\n",
        "# use grains to obtain psd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ELNAEunkox",
        "outputId": "e11d5ae3-70e5-4113-c6fe-e7d7e8aa58b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Doutorado'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 287 (delta 15), reused 0 (delta 0), pack-reused 250\u001b[K\n",
            "Receiving objects: 100% (287/287), 78.56 MiB | 38.09 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n",
            "/content/marquesgabi_out_2020/marquesgabi_fev_2020/Doutorado/marquesgabi_set_2020/Doutorado/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmPJiuSnnxT9",
        "outputId": "a7dbbd4d-93f7-4999-9bb2-fb2720e787e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "k=0\n",
        "for Item in img_name:\n",
        "  print(k,Item)\n",
        "  k=k+1\n",
        "\n",
        "img=ww[21]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Fotos_Grandes-3cdAmostra/Q6-8-4.jpg\n",
            "1 Fotos_Grandes-3cdAmostra/Q6-5-3.jpg\n",
            "2 Fotos_Grandes-3cdAmostra/Q6-7-4.jpg\n",
            "3 Fotos_Grandes-3cdAmostra/Q6-8-2.jpg\n",
            "4 Fotos_Grandes-3cdAmostra/Q6-3-2.jpg\n",
            "5 Fotos_Grandes-3cdAmostra/Q6-7-2.jpg\n",
            "6 Fotos_Grandes-3cdAmostra/Q6-4-4.jpg\n",
            "7 Fotos_Grandes-3cdAmostra/Q6-9-5.jpg\n",
            "8 Fotos_Grandes-3cdAmostra/Q6-2-5.jpg\n",
            "9 Fotos_Grandes-3cdAmostra/Q6-8-3.jpg\n",
            "10 Fotos_Grandes-3cdAmostra/Q6-9-3.jpg\n",
            "11 Fotos_Grandes-3cdAmostra/Q6-1-2.jpg\n",
            "12 Fotos_Grandes-3cdAmostra/Q6-6-3.jpg\n",
            "13 Fotos_Grandes-3cdAmostra/Q6-3-4.jpg\n",
            "14 Fotos_Grandes-3cdAmostra/Q6-1-4.jpg\n",
            "15 Fotos_Grandes-3cdAmostra/Q6-6-2.jpg\n",
            "16 Fotos_Grandes-3cdAmostra/Q6-4-3.jpg\n",
            "17 Fotos_Grandes-3cdAmostra/Q6-7-3.jpg\n",
            "18 Fotos_Grandes-3cdAmostra/Q6-2-2.jpg\n",
            "19 Fotos_Grandes-3cdAmostra/Q6-9-2.jpg\n",
            "20 Fotos_Grandes-3cdAmostra/Q6-1-5.jpg\n",
            "21 Fotos_Grandes-3cdAmostra/Q6-6-5.jpg\n",
            "22 Fotos_Grandes-3cdAmostra/Q6-2-1.jpg\n",
            "23 Fotos_Grandes-3cdAmostra/Q6-5-2.jpg\n",
            "24 Fotos_Grandes-3cdAmostra/Q6-4-1.jpg\n",
            "25 Fotos_Grandes-3cdAmostra/Q6-3-1.jpg\n",
            "26 Fotos_Grandes-3cdAmostra/Q6-5-4.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg08LdDEsYLd"
      },
      "source": [
        "df=Segmenta(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O2xFH1Ishc2",
        "outputId": "0ad43ad3-8606-485d-feca-b07fd0e54c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_pred,confusion_matrix,METRICS=AnnGrain(ANN_dat,df.drop('Width',axis=1)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_2_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_2_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 6.7964 - accuracy: 0.4402 \n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.9458 - accuracy: 0.5452\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.9408 - accuracy: 0.5277\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.1919 - accuracy: 0.4956\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.5073\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7872\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.6910\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.7026\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.6443\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8105\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.6851\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.7726\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8222\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.9388\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.9067\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.6618\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.2177 - accuracy: 0.4956\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.5627\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8776\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.5429 - accuracy: 0.4956\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.7338 - accuracy: 0.4956\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.0377 - accuracy: 0.5131\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.7405\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.9971\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9971\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2342 - accuracy: 0.9679\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9825\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9942\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7172\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.6735\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.9563\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1668 - accuracy: 0.9913\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.6647\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.6472\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9155\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.9971\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.7872\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.6880\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.9155\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0911 - accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.9872 - accuracy: 0.7988\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.8380 - accuracy: 0.4956\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 3.1506 - accuracy: 0.4956\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.4499 - accuracy: 0.4956\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.5637 - accuracy: 0.5131\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7888 - accuracy: 0.5860\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.7959\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1243 - accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1253 - accuracy: 0.9971\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9679\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9650\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9971\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0905 - accuracy: 0.9971\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9971\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1230 - accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9971\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9971\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1003 - accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0487 - accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0866 - accuracy: 0.9971\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1123 - accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9971\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1243 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9679\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.7522\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.8659\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9971\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9971\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9971\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9971\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0966 - accuracy: 0.9883\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2038 - accuracy: 0.9329\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9942\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.8805\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.7376\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9708\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9971\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.9621\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9679\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9971\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.7726\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.8358 - accuracy: 0.6356\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 0.9738\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.9971\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9446\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9796\n",
            "Predicted   0   1\n",
            "Actual           \n",
            "0          72   0\n",
            "1           0  75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S5a4-cashbB"
      },
      "source": [
        "# print(y_pred.ravel())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o9IdMKmw5ri"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA2XIpGOyipM"
      },
      "source": [
        "Grain=[]; Ind=[]; Size=[]\n",
        "k=0\n",
        "for item in y_pred:\n",
        "  if(item == 0):\n",
        "    Ind.append(k)\n",
        "  k=k+1\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "df_size = df.drop(df.index[Ind])\n",
        "\n",
        "Width=np.array(df_size['Width'])\n",
        "\n",
        "# print(Width)\n",
        "\n",
        "# print(df_size.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06lkGMZo9uKV"
      },
      "source": [
        "# pd.set_option('display.max_rows', None)\n",
        "# print(df_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIeDfpxy0yMh"
      },
      "source": [
        "# print(len(y_pred.ravel()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciUjF5tmdqLC",
        "outputId": "f0090152-5d96-4e8d-92b7-71af70a19f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "Size=28\n",
        "qual_img=40\n",
        "L = Width[qual_img]\n",
        "data=np.array(df_size.drop('Width',axis=1).iloc[qual_img]).reshape(Size,Size)\n",
        "img = Image.fromarray(data.astype('uint8'), mode='L')\n",
        "img=np.float32(img)\n",
        "img28=cv2.resize(img,(Size,Size), interpolation = cv2.INTER_AREA)\n",
        "Foto=np.array(img28).reshape(28,28)\n",
        "plt.imshow(Foto, cmap = \"gray\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fad12b7a0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-MTA4fXg2W0"
      },
      "source": [
        "mean_value = np.mean(img)\n",
        "img_new = img.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbcfWPMdewq3",
        "outputId": "4e9dd4df-eee0-47a5-f96a-cad955d24011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "\n",
        "for i in range(28):\n",
        "  for j in range(28):\n",
        "    if img[i,j] < mean_value:\n",
        "      img_new[i,j] = 255\n",
        "    else:\n",
        "      img_new[i,j] = 0\n",
        "\n",
        "img28=cv2.resize(img_new,(Size,Size), interpolation = cv2.INTER_AREA)\n",
        "Foto=np.array(img28).reshape(28,28)\n",
        "plt.imshow(Foto, cmap = \"gray\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fad12c87cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spRNBSwifDqQ",
        "outputId": "3de4cb75-8073-4667-fea8-b5548a77f5b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "L = Width[qual_img]\n",
        "Area = np.sum(img_new) / (255.0 * 28 * 28)* L*L\n",
        "print(Area)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12355.94005102041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GP_DXsWibOX"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(df_size) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ydbrnjewBYL",
        "outputId": "0b3d24bd-2637-4d0e-d191-aa3176a8cb0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_size.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L3IfgxMs3dI",
        "outputId": "ebd2b318-6bc8-4cab-8218-9dac9381c0ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# print(Area_All)\n",
        "# print(Diameter_All)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.561389777981505, 2.0747341322448976, 0.8586487193877549, 1.8867121773692603, 1.3366216832142856, 2.3552467956792094, 0.7666174331632652, 1.6948981529942602, 0.5813234130994896, 2.5792226775000002, 1.0235146568877551, 0.6709474731122449, 1.2353475047831632, 2.8845687698150515, 0.8094730948278059, 2.302372698979591, 2.4827839038424746, 1.6580267578124999, 2.472622014030612, 2.5893587209821423, 0.9029979624489795, 0.40562832225765305, 1.4035020436320151, 1.6741498206409438, 0.9300329174617347, 1.5968218843526787, 1.4290811926530615, 1.6326315918367347, 2.743947301339285, 1.557716999234694, 1.5087294870153058, 1.4603635102040817, 1.6158735351562499, 2.09781414, 2.319017735318878, 1.0088088599617344, 1.0439216341645405, 1.1114686463647958, 0.6802518459374999, 0.53511736359375, 1.4815081019674745, 1.08936666984375, 1.9425901069802298, 2.540319821977041, 1.252858775510204, 1.0237472738552296, 2.2780950426562496, 0.5422920906122447, 0.4903920487882652, 0.7165722096045919, 1.17680556796875, 0.6659221207557399, 2.3098878634534437, 1.6530229695535714, 2.017952192841199, 2.3618394449999998, 1.3282167320758926, 2.2036580718749996, 1.0698667610969386, 2.0323326930612247, 1.0412018050063776, 1.5974426550765308, 1.5129438151913264, 1.4806582318239794, 2.3081286307270408, 2.026454411823979, 0.8401433590561223, 1.9169510067091833, 1.5699886530612246, 1.8205604081632656, 0.6002453734438775, 1.9409312008354591, 0.8303885871715561, 1.12174783875, 0.8422355353316325, 1.6620032691677291, 1.5680610368494898, 1.6009715202359693, 2.23601339445153, 1.8558911173947703, 1.2232624339285711, 2.2563845845025514, 2.2897780425, 1.8446731985491072, 2.1764524393239797, 1.4898635015625, 1.323873478125, 1.6277530588679847, 0.5716951199999999, 2.5720525385873727, 1.8212643765401781, 0.9060224418367346, 2.2786162514827804, 2.3982823110937503, 0.5392578232653061, 1.35234420440051, 1.0104379434183675, 1.8083643051466833, 1.3445811292729593, 1.782671829910714, 1.5925921095535711, 1.802582374132653, 1.7541258586989794, 0.6356705976562501, 2.68043675174426, 0.8838646433609693, 0.5773672423469387, 0.867702581632653, 1.2900938545503824, 1.0277692074585456, 0.9546783869387755, 0.7288412635044642, 1.6074349379081632, 2.63904790752551, 2.202878093877551, 2.709987671077806, 1.7194385548469384, 0.7349957487149235, 1.83545997609375, 1.7166356809725765, 0.7570718789062502, 0.9647012571428571, 0.9472770074904333, 1.7640900011479588, 1.3463808902678571, 1.4716808380102038, 1.8205897720408162, 1.2432262001785714, 2.5578385866103317, 1.8389146668749998, 1.9858252049999998, 0.9290570273437501, 1.7736690485778057, 2.0254823451275508, 1.3577332406154334, 1.700932429830995, 0.7216631718750001, 0.5750426020408163, 1.860676970625, 1.4918721743112242, 0.8364398399999999, 1.1176766594770409, 1.4834637056249997, 1.3173962961352041, 2.4806603755102037, 2.950051134375, 2.2050436798469386, 2.0750204300510204, 1.7447318648724486, 1.6821372541454076]\n",
            "[1.4099727692658848, 1.6253102909863077, 1.0455933743863794, 1.5499150150120893, 1.3045457383391752, 1.7317024449568543, 0.9879714730632838, 1.4690171383244242, 0.860327819984153, 1.8121722621403042, 1.1415688046567898, 0.9242709858080813, 1.2541504274128499, 1.9164412402253779, 1.0152108917529987, 1.7121541890435692, 1.7779703730389274, 1.4529505271260634, 1.774328077737169, 1.8157295831316198, 1.0722558997764098, 0.7186529206529547, 1.3367850624049094, 1.4599978614543685, 1.0881887191189286, 1.4258810501077392, 1.3489116676503201, 1.4417805327824509, 1.8691447811056556, 1.408313488869508, 1.3859920797666498, 1.363595457193991, 1.434361908394092, 1.6343255246592054, 1.7183320649834177, 1.1333381373546367, 1.152893015948508, 1.1896074282236642, 0.9306575904309363, 0.8254287300560762, 1.3734317242842915, 1.1777201377073914, 1.5726991267939774, 1.7984536840340808, 1.263008051022663, 1.1416985210147628, 1.7031032543492701, 0.8309438817180219, 0.7901813392765704, 0.9551796029683738, 1.2240732762389415, 0.9208031156876655, 1.7149462299596276, 1.4507564279337715, 1.6029150106323329, 1.7341243841458862, 1.3004376445096995, 1.6750476411690776, 1.167131812532907, 1.6086162851543127, 1.1513901650542921, 1.4261581815809112, 1.3879264730035539, 1.373037731818006, 1.7142930458288315, 1.6062882346382685, 1.0342648345549061, 1.5622860900174502, 1.4138499347041908, 1.5225010690481167, 0.8742174477857728, 1.572027467480773, 1.0282429609210009, 1.1950956896908727, 1.0355518285269085, 1.4546918181468786, 1.4129817127886657, 1.4277325553335285, 1.6872998181630887, 1.5372032921477075, 1.2480008431354688, 1.6949684602137787, 1.7074647733927844, 1.5325504440330249, 1.6646757380891326, 1.3772992145670355, 1.2983096951709292, 1.4396247995968745, 0.853173390534488, 1.8096516248344336, 1.522795398478859, 1.0740500925767122, 1.7032980709975802, 1.747451824206722, 0.8286159456522625, 1.3121959149212976, 1.1342528585201521, 1.517392811568673, 1.3084241914971588, 1.5065750127782278, 1.4239913105482074, 1.514965069362422, 1.4944639205206878, 0.8996448979243825, 1.8473868218330074, 1.0608352445693099, 0.8573953608405008, 1.0510914517792849, 1.281638994426028, 1.1439389834240887, 1.102512709565938, 0.9633221260453976, 1.430611662378573, 1.8330685083520648, 1.6747511759529283, 1.8575423194535865, 1.479613855968307, 0.9673808208126049, 1.5287184908743725, 1.4784073974779954, 0.9818013314466365, 1.10828506687134, 1.0982306432417586, 1.4987024887993878, 1.309299580602075, 1.3688689638470055, 1.5225133472330359, 1.2581433786012588, 1.804644352087627, 1.5301564865263744, 1.5901041412240304, 1.0876176472125487, 1.5027659737703853, 1.6059029295008191, 1.3148078388696165, 1.4716298558344385, 0.9585666843836471, 0.855667564434794, 1.5391840367473204, 1.37822735715958, 1.0319826941765797, 1.1929250274320113, 1.374337896290833, 1.295129746522323, 1.7772098601901716, 1.9380716610272892, 1.6755741735445389, 1.62542242745519, 1.4904568444994064, 1.46347657024298]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aecOBA5LNmD",
        "outputId": "781b5b22-2095-4bc5-ce75-1a84d92c06e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "d = 1.6343255246592054\n",
        "r = d / 2.0\n",
        "Area = np.pi * d**2 / 4; print('Area=',Area)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area= 2.09781414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJFWGVQJLwRo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pq4DTm1np4i"
      },
      "source": [
        ""
      ]
    }
  ]
}