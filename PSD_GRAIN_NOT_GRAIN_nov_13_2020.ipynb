{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_GRAIN_NOT_GRAIN_nov_13_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/marquesgabi_out_2020/blob/main/PSD_GRAIN_NOT_GRAIN_nov_13_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sog7Z9pyhUD_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "#import random\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#import scikit-image\n",
        "import skimage\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZEvJvfoibE4",
        "outputId": "85d49200-c53f-43d7-bdc4-8412ef32ebd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install mahotas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mahotas in /usr/local/lib/python3.6/dist-packages (1.4.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mahotas) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VcTdaNVh9EE",
        "outputId": "e5ca2f41-19d3-4ab7-97e1-457a746b0ba1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_fev_2020 #clonar do Github\n",
        "%cd marquesgabi_fev_2020\n",
        "import Go2BlackWhite\n",
        "import Go2Mahotas"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_fev_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_a6PJ1iUnT"
      },
      "source": [
        "import mahotas.features.texture as mht\n",
        "import mahotas.features"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj62HANgnpnR",
        "outputId": "5d2222e5-f1f4-41c4-f3e9-cc719486d62a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_out_2020/\n",
        "%cd marquesgabi_out_2020\n",
        "\n",
        "from Get_PSDArea import PSDArea\n",
        "from histogram import PSD\n",
        "from GetBetterSegm import GetBetter"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_out_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/marquesgabi_out_2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L6KJ4jc3ahG",
        "outputId": "e13983c5-4a44-4bf4-8b72-924727043a84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Areas_ImageJ.csv\t\t imageJ_jpg.zip\n",
            "Areas_ImageJ.xlsx\t\t IMAGEJ_Zuados.zip\n",
            "Doutorado\t\t\t PSD_GRAIN_NOT_GRAIN_out_09_2020.ipynb\n",
            "GetBetterSegm.py\t\t PSD_GRAIN_NOT_GRAIN_out_19_2020.ipynb\n",
            "Get_PSDArea.py\t\t\t PSD_GRAIN_NOT_GRAIN_out_28_2020.ipynb\n",
            "Histogram_PSD_out_19_2020.ipynb  PSD_USA_ROTINAS_out_05_2020.ipynb\n",
            "Histogram_PSD_out_23_2020.ipynb  __pycache__\n",
            "histogram.py\t\t\t README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v7SRrc8mH2N",
        "outputId": "0e0c502a-f271-4282-b473-883b5ab60edd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "\n",
        "Transfere='Fotos_Grandes_3cdAmostra.zip'\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/marquesgabi_out_2020/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kA4IWSmasoD"
      },
      "source": [
        "Size=1200 # tamanho da foto\n",
        "ww,img_name=Go2BlackWhite.BlackWhite(Transfere,Size) #Pegamos a primeira foto Grande\n",
        "img=ww[0] \n",
        "# this is the big image we want to segment \n",
        "# ww[0], change it if you want to segment another picture"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_k1Ktz3izJv",
        "outputId": "ebfadac1-3aad-4a47-d365-88eb04d3dca3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "# %cd Doutorado\n",
        "Transfere='FotosTreino882_and_Segm.zip'\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()\n",
        "\n",
        "\"\"\"# First step: get the segmented file (photos stored in csv file)\"\"\"\n",
        "\n",
        "labels = [] #name files\n",
        "\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "\n",
        "Num=len(labels)\n",
        "df=pd.read_csv(labels[0])\n",
        "for i in range(1,Num):\n",
        "  df_new=pd.read_csv(labels[i])\n",
        "  df_new = df_new[~df_new['Type'].isin(['G'])] # drop grain row which is not in 882\n",
        "  frames = [df, df_new]\n",
        "  df= pd.concat(frames, ignore_index=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHgqAnaFyCjp",
        "outputId": "ba69e83f-750f-4acc-e24b-e5e30a36c994",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_set_2020\n",
        "%cd marquesgabi_set_2020"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'marquesgabi_set_2020' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/marquesgabi_out_2020/Doutorado/marquesgabi_set_2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc4rFvzkyWCi"
      },
      "source": [
        "from big_segment import Segmenta  # got image provided segmented\n",
        "from ANN_FIND_GRAIN import AnnGrain  # got image provided segmented\n",
        "from psd_mahotas import Mahotas"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPoCxCp4kuRm",
        "outputId": "88d2e094-6a0f-4cad-f1a7-d1d91889ab2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado\n",
        "Transfere='FotosTreino882_and_Segm.zip'\n",
        "file_name = zipfile.ZipFile(Transfere, 'r')\n",
        "file_name.extractall()\n",
        "\n",
        "\"\"\"# First step: get the segmented file (photos stored in csv file)\"\"\"\n",
        "\n",
        "labels = [] #name files\n",
        "\n",
        "with zipfile.ZipFile(Transfere, \"r\") as f:\n",
        "  for f in f.namelist():\n",
        "    labels.append(f)\n",
        "\n",
        "Num=len(labels)\n",
        "ANN_dat=pd.read_csv(labels[0])\n",
        "for i in range(1,Num):\n",
        "  df_new=pd.read_csv(labels[i])\n",
        "  df_new = df_new[~df_new['Type'].isin(['G'])] # drop grain row which is not in 882\n",
        "  frames = [ANN_dat, df_new]\n",
        "  ANN_dat= pd.concat(frames, ignore_index=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/marquesgabi_out_2020/Doutorado/marquesgabi_set_2020/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnTtH3KDP863"
      },
      "source": [
        "df=Segmenta(img)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nm-Uwb9qwBK",
        "outputId": "6f6df0fa-9547-4941-b0ff-9050843df674",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Width           0           1  ...         781        782         783\n",
            "0     184   54.517956   53.300560  ...  109.341194  92.042053   67.657364\n",
            "1     119   92.979248   87.442909  ...   91.640137  89.868515   88.844292\n",
            "2     110   63.310074   64.487610  ...   96.864136  97.434052  100.583145\n",
            "3     183   71.788437   73.715942  ...   80.835281  78.238197   69.501900\n",
            "4     178   89.475449   80.335449  ...   61.246433  57.591217   50.572407\n",
            "..    ...         ...         ...  ...         ...        ...         ...\n",
            "45    126   43.234570   39.061729  ...   52.629631  55.975307   58.839504\n",
            "46    151   67.369987   71.066223  ...   61.236877  63.755630   63.630718\n",
            "47    144  109.952164  114.787041  ...    0.000000   0.000000    0.000000\n",
            "48    180   32.993584   74.000008  ...    0.000000   0.120988    0.535802\n",
            "49    142   55.274750   53.952785  ...  101.389618  94.064270   99.618729\n",
            "\n",
            "[150 rows x 785 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NisVTw0QfAqC",
        "outputId": "d29a7609-3ebf-4403-e33a-73486de7beba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred,confusion_matrix,METRICS=AnnGrain(ANN_dat,df.drop('Width',axis=1)) \n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 13.7670 - accuracy: 0.4490\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.5927 - accuracy: 0.4956\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.9043 - accuracy: 0.5481\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 3.2279 - accuracy: 0.4956\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 3.2832 - accuracy: 0.4956\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.6032 - accuracy: 0.4956\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.6758 - accuracy: 0.4956\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7126 - accuracy: 0.5452\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.8426\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8426\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8076\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.6676\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.7230\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.8047\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.9649 - accuracy: 0.5044\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.6647\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.9242\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7865 - accuracy: 0.5481\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5899 - accuracy: 0.6181\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9592\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.6822\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.8397\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.9359\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.9373 - accuracy: 0.5539\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7237 - accuracy: 0.6035\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9359\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.7959\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.6647\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1956 - accuracy: 0.9417\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9971\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9563\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9854\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8280\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9679\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9942\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8598 - accuracy: 0.6181\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8405 - accuracy: 0.6210\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9446\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0905 - accuracy: 0.9971\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9767\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1187 - accuracy: 0.9942\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8746\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8771 - accuracy: 0.5948\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.7784\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9971\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9942\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9125\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.9971\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.9942\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.8392 - accuracy: 0.6851\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.1397 - accuracy: 0.5918\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2794 - accuracy: 0.8630\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9971\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.9854\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.8397\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.6793\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9592\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9971\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9971\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8105\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.8776\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.9971\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.9796\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.9825\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9621\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8717\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9913\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9971\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9213\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9971\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9971\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9796\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0947 - accuracy: 0.9971\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9417\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8192\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9971\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9883\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.0512 - accuracy: 0.6152\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7493\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 0.9971\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1177 - accuracy: 0.9767\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9679\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.9971\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9971\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1188 - accuracy: 0.9534\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.9125\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9971\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 0.9971\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.8863\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1019 - accuracy: 0.9738\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Predicted   0   1\n",
            "Actual           \n",
            "0          72   0\n",
            "1           2  73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuIlULfFx-lF"
      },
      "source": [
        "# y_pred,confusion_matrix,METRICS=AnnGrain(ANN_dat,df.drop('Width',axis=1)) \n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FWWKD60grG_",
        "outputId": "7c373aeb-5dd0-47d4-e5d2-00d0100b38df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(confusion_matrix)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted   0   1\n",
            "Actual           \n",
            "0          72   0\n",
            "1           2  73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XdZVmRmk9s6",
        "outputId": "ca5eae3f-f625-47b0-de04-88bd23f819fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv01JmHfmz-1"
      },
      "source": [
        "# open file to get df \n",
        "# use df and ANN to get grains and no grains\n",
        "# use grains to obtain psd"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ELNAEunkox",
        "outputId": "9a7a337c-76e8-4a53-80bc-3b1be4988997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/marquesgabi/Doutorado\n",
        "%cd Doutorado"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Doutorado' already exists and is not an empty directory.\n",
            "/content/marquesgabi_fev_2020/marquesgabi_out_2020/Doutorado/marquesgabi_set_2020/Doutorado/Doutorado\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmPJiuSnnxT9",
        "outputId": "f742a39b-f324-4608-c9a8-9174c5e05603",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "k=0\n",
        "for Item in img_name:\n",
        "  print(k,Item)\n",
        "  k=k+1\n",
        "\n",
        "img=ww[21]\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Fotos_Grandes-3cdAmostra/Q6-8-4.jpg\n",
            "1 Fotos_Grandes-3cdAmostra/Q6-5-3.jpg\n",
            "2 Fotos_Grandes-3cdAmostra/Q6-7-4.jpg\n",
            "3 Fotos_Grandes-3cdAmostra/Q6-8-2.jpg\n",
            "4 Fotos_Grandes-3cdAmostra/Q6-3-2.jpg\n",
            "5 Fotos_Grandes-3cdAmostra/Q6-7-2.jpg\n",
            "6 Fotos_Grandes-3cdAmostra/Q6-4-4.jpg\n",
            "7 Fotos_Grandes-3cdAmostra/Q6-9-5.jpg\n",
            "8 Fotos_Grandes-3cdAmostra/Q6-2-5.jpg\n",
            "9 Fotos_Grandes-3cdAmostra/Q6-8-3.jpg\n",
            "10 Fotos_Grandes-3cdAmostra/Q6-9-3.jpg\n",
            "11 Fotos_Grandes-3cdAmostra/Q6-1-2.jpg\n",
            "12 Fotos_Grandes-3cdAmostra/Q6-6-3.jpg\n",
            "13 Fotos_Grandes-3cdAmostra/Q6-3-4.jpg\n",
            "14 Fotos_Grandes-3cdAmostra/Q6-1-4.jpg\n",
            "15 Fotos_Grandes-3cdAmostra/Q6-6-2.jpg\n",
            "16 Fotos_Grandes-3cdAmostra/Q6-4-3.jpg\n",
            "17 Fotos_Grandes-3cdAmostra/Q6-7-3.jpg\n",
            "18 Fotos_Grandes-3cdAmostra/Q6-2-2.jpg\n",
            "19 Fotos_Grandes-3cdAmostra/Q6-9-2.jpg\n",
            "20 Fotos_Grandes-3cdAmostra/Q6-1-5.jpg\n",
            "21 Fotos_Grandes-3cdAmostra/Q6-6-5.jpg\n",
            "22 Fotos_Grandes-3cdAmostra/Q6-2-1.jpg\n",
            "23 Fotos_Grandes-3cdAmostra/Q6-5-2.jpg\n",
            "24 Fotos_Grandes-3cdAmostra/Q6-4-1.jpg\n",
            "25 Fotos_Grandes-3cdAmostra/Q6-3-1.jpg\n",
            "26 Fotos_Grandes-3cdAmostra/Q6-5-4.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg08LdDEsYLd"
      },
      "source": [
        "df=Segmenta(img)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O2xFH1Ishc2",
        "outputId": "a11c91b0-c47d-45f3-b3b1-30858527bf6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred,confusion_matrix,METRICS=AnnGrain(ANN_dat,df.drop('Width',axis=1)) "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_1_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input Tensor(\"flatten_1_input:0\", shape=(None, 28, 28), dtype=float32), but it was called on an input with incompatible shape (None, 784).\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 26.9950 - accuracy: 0.4898\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 3.5359 - accuracy: 0.4956\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.9529 - accuracy: 0.4956\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.5015\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.9689 - accuracy: 0.4956\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.5860\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.2446 - accuracy: 0.5044\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 3.5588 - accuracy: 0.4956\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 3.6842 - accuracy: 0.4956\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 3.1766 - accuracy: 0.4956\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 2.5225 - accuracy: 0.4956\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.8233 - accuracy: 0.4956\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.1545 - accuracy: 0.4956\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.5743\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8309\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3114 - accuracy: 0.8571\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.9534\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2818 - accuracy: 0.9913\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.7376\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8601\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1921 - accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9825\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2920 - accuracy: 0.8921\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9854\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9971\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9883\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.7085\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.8746\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9971\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.9621\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9854\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1216 - accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1237 - accuracy: 0.9971\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9329\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9767\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1520 - accuracy: 0.9854\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8717\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9679\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1169 - accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 0.2390 - accuracy: 0.9213\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8047\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9738\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 0.9971\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9796\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1304 - accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1512 - accuracy: 0.9971\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9971\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9883\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9971\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0848 - accuracy: 0.9971\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 0.9767\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1687 - accuracy: 0.9942\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.9942\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9621\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0600 - accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9971\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9971\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.9942\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9971\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0774 - accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9971\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0909 - accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1040 - accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9971\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9942\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9942\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.9854\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2382 - accuracy: 0.8921\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9942\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9971\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.7273 - accuracy: 0.7143\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 1.3401 - accuracy: 0.5598\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7493\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9971\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9009\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8017\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.9854\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9971\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9971\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.1618 - accuracy: 0.9679\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 0.9971\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.8542\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.1595 - accuracy: 0.9417\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Predicted   0   1\n",
            "Actual           \n",
            "0          72   0\n",
            "1           3  72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S5a4-cashbB"
      },
      "source": [
        "# print(y_pred.ravel())"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o9IdMKmw5ri"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA2XIpGOyipM"
      },
      "source": [
        "Grain=[]; Ind=[]; Size=[]\n",
        "k=0\n",
        "for item in y_pred:\n",
        "  if(item == 0):\n",
        "    Ind.append(k)\n",
        "  k=k+1\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "df_size = df.drop(df.index[Ind])\n",
        "\n",
        "Width=np.array(df_size['Width'])\n",
        "\n",
        "# print(Width)\n",
        "\n",
        "# print(df_size.shape)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06lkGMZo9uKV"
      },
      "source": [
        "# pd.set_option('display.max_rows', None)\n",
        "# print(df_size)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIqWqspygJtw",
        "outputId": "ee678f46-bd19-4ee3-9884-7369761f2d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Width</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>139</td>\n",
              "      <td>110.821945</td>\n",
              "      <td>110.604362</td>\n",
              "      <td>109.872459</td>\n",
              "      <td>111.563370</td>\n",
              "      <td>115.453957</td>\n",
              "      <td>119.006668</td>\n",
              "      <td>121.960815</td>\n",
              "      <td>124.348480</td>\n",
              "      <td>123.308571</td>\n",
              "      <td>124.294441</td>\n",
              "      <td>125.204224</td>\n",
              "      <td>135.220688</td>\n",
              "      <td>141.177170</td>\n",
              "      <td>143.647842</td>\n",
              "      <td>143.159821</td>\n",
              "      <td>113.672005</td>\n",
              "      <td>224.592712</td>\n",
              "      <td>231.334473</td>\n",
              "      <td>208.465240</td>\n",
              "      <td>200.593811</td>\n",
              "      <td>191.219345</td>\n",
              "      <td>196.846603</td>\n",
              "      <td>165.016541</td>\n",
              "      <td>147.228027</td>\n",
              "      <td>154.278290</td>\n",
              "      <td>165.905640</td>\n",
              "      <td>156.989273</td>\n",
              "      <td>143.077469</td>\n",
              "      <td>112.698662</td>\n",
              "      <td>115.531235</td>\n",
              "      <td>115.863358</td>\n",
              "      <td>115.977936</td>\n",
              "      <td>117.855583</td>\n",
              "      <td>122.143463</td>\n",
              "      <td>124.985191</td>\n",
              "      <td>127.135803</td>\n",
              "      <td>127.905640</td>\n",
              "      <td>129.597061</td>\n",
              "      <td>129.500793</td>\n",
              "      <td>...</td>\n",
              "      <td>158.378021</td>\n",
              "      <td>135.394455</td>\n",
              "      <td>111.836395</td>\n",
              "      <td>72.760368</td>\n",
              "      <td>56.361263</td>\n",
              "      <td>60.225559</td>\n",
              "      <td>64.225868</td>\n",
              "      <td>65.749489</td>\n",
              "      <td>63.890377</td>\n",
              "      <td>62.785149</td>\n",
              "      <td>68.363335</td>\n",
              "      <td>72.122040</td>\n",
              "      <td>85.137726</td>\n",
              "      <td>89.135025</td>\n",
              "      <td>93.537491</td>\n",
              "      <td>83.969666</td>\n",
              "      <td>72.680496</td>\n",
              "      <td>73.126129</td>\n",
              "      <td>66.627350</td>\n",
              "      <td>63.845295</td>\n",
              "      <td>56.915066</td>\n",
              "      <td>47.993580</td>\n",
              "      <td>45.224155</td>\n",
              "      <td>45.128510</td>\n",
              "      <td>48.920135</td>\n",
              "      <td>30.923450</td>\n",
              "      <td>100.965469</td>\n",
              "      <td>132.422333</td>\n",
              "      <td>144.825012</td>\n",
              "      <td>144.314377</td>\n",
              "      <td>120.905380</td>\n",
              "      <td>88.054703</td>\n",
              "      <td>51.493191</td>\n",
              "      <td>59.828266</td>\n",
              "      <td>64.959785</td>\n",
              "      <td>65.074165</td>\n",
              "      <td>66.568192</td>\n",
              "      <td>67.966774</td>\n",
              "      <td>68.516632</td>\n",
              "      <td>72.946121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>71.004395</td>\n",
              "      <td>79.708069</td>\n",
              "      <td>72.399132</td>\n",
              "      <td>64.778587</td>\n",
              "      <td>86.935028</td>\n",
              "      <td>92.872124</td>\n",
              "      <td>123.330444</td>\n",
              "      <td>128.219574</td>\n",
              "      <td>128.626419</td>\n",
              "      <td>128.281662</td>\n",
              "      <td>130.303162</td>\n",
              "      <td>130.141296</td>\n",
              "      <td>130.725525</td>\n",
              "      <td>137.218994</td>\n",
              "      <td>141.407455</td>\n",
              "      <td>150.733154</td>\n",
              "      <td>153.390579</td>\n",
              "      <td>140.938721</td>\n",
              "      <td>102.562035</td>\n",
              "      <td>93.230782</td>\n",
              "      <td>92.303513</td>\n",
              "      <td>91.832703</td>\n",
              "      <td>93.738708</td>\n",
              "      <td>99.541222</td>\n",
              "      <td>115.706566</td>\n",
              "      <td>122.514984</td>\n",
              "      <td>116.938034</td>\n",
              "      <td>117.648407</td>\n",
              "      <td>104.955612</td>\n",
              "      <td>115.654419</td>\n",
              "      <td>116.121864</td>\n",
              "      <td>124.684021</td>\n",
              "      <td>110.212173</td>\n",
              "      <td>88.412888</td>\n",
              "      <td>122.216560</td>\n",
              "      <td>127.245819</td>\n",
              "      <td>132.005554</td>\n",
              "      <td>131.123840</td>\n",
              "      <td>127.642975</td>\n",
              "      <td>...</td>\n",
              "      <td>120.995735</td>\n",
              "      <td>119.785873</td>\n",
              "      <td>125.237152</td>\n",
              "      <td>135.556259</td>\n",
              "      <td>145.583664</td>\n",
              "      <td>150.436020</td>\n",
              "      <td>150.422943</td>\n",
              "      <td>150.723785</td>\n",
              "      <td>139.935028</td>\n",
              "      <td>124.625511</td>\n",
              "      <td>126.451042</td>\n",
              "      <td>119.842194</td>\n",
              "      <td>119.768768</td>\n",
              "      <td>117.118752</td>\n",
              "      <td>111.967522</td>\n",
              "      <td>108.687141</td>\n",
              "      <td>108.661240</td>\n",
              "      <td>110.093765</td>\n",
              "      <td>113.034813</td>\n",
              "      <td>116.918503</td>\n",
              "      <td>120.452202</td>\n",
              "      <td>121.538338</td>\n",
              "      <td>95.645401</td>\n",
              "      <td>61.221298</td>\n",
              "      <td>19.774427</td>\n",
              "      <td>67.149155</td>\n",
              "      <td>139.696854</td>\n",
              "      <td>136.529785</td>\n",
              "      <td>119.374733</td>\n",
              "      <td>120.614182</td>\n",
              "      <td>127.065338</td>\n",
              "      <td>130.316803</td>\n",
              "      <td>140.121292</td>\n",
              "      <td>147.502975</td>\n",
              "      <td>148.223618</td>\n",
              "      <td>144.579956</td>\n",
              "      <td>152.067764</td>\n",
              "      <td>133.476486</td>\n",
              "      <td>117.320969</td>\n",
              "      <td>112.165230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>181</td>\n",
              "      <td>120.460930</td>\n",
              "      <td>120.903580</td>\n",
              "      <td>113.302681</td>\n",
              "      <td>100.454842</td>\n",
              "      <td>97.937157</td>\n",
              "      <td>101.705170</td>\n",
              "      <td>101.828186</td>\n",
              "      <td>103.882324</td>\n",
              "      <td>106.951256</td>\n",
              "      <td>106.318314</td>\n",
              "      <td>111.944511</td>\n",
              "      <td>121.233002</td>\n",
              "      <td>136.879623</td>\n",
              "      <td>143.246216</td>\n",
              "      <td>139.331619</td>\n",
              "      <td>127.885078</td>\n",
              "      <td>123.931198</td>\n",
              "      <td>118.294388</td>\n",
              "      <td>119.608353</td>\n",
              "      <td>125.265747</td>\n",
              "      <td>112.396080</td>\n",
              "      <td>106.469948</td>\n",
              "      <td>106.003021</td>\n",
              "      <td>94.242821</td>\n",
              "      <td>74.157082</td>\n",
              "      <td>77.127136</td>\n",
              "      <td>76.918198</td>\n",
              "      <td>72.882057</td>\n",
              "      <td>125.161385</td>\n",
              "      <td>123.581512</td>\n",
              "      <td>118.222855</td>\n",
              "      <td>105.771347</td>\n",
              "      <td>99.424477</td>\n",
              "      <td>102.688103</td>\n",
              "      <td>103.243896</td>\n",
              "      <td>103.586014</td>\n",
              "      <td>105.126587</td>\n",
              "      <td>105.662956</td>\n",
              "      <td>112.223129</td>\n",
              "      <td>...</td>\n",
              "      <td>63.172127</td>\n",
              "      <td>59.852451</td>\n",
              "      <td>59.130798</td>\n",
              "      <td>76.505356</td>\n",
              "      <td>89.239769</td>\n",
              "      <td>99.790062</td>\n",
              "      <td>105.460968</td>\n",
              "      <td>110.308685</td>\n",
              "      <td>112.783775</td>\n",
              "      <td>117.273254</td>\n",
              "      <td>117.400421</td>\n",
              "      <td>115.535156</td>\n",
              "      <td>212.645370</td>\n",
              "      <td>132.180801</td>\n",
              "      <td>69.909309</td>\n",
              "      <td>87.043472</td>\n",
              "      <td>86.175217</td>\n",
              "      <td>82.112030</td>\n",
              "      <td>78.369530</td>\n",
              "      <td>74.985443</td>\n",
              "      <td>69.285255</td>\n",
              "      <td>55.492386</td>\n",
              "      <td>43.959190</td>\n",
              "      <td>38.858799</td>\n",
              "      <td>56.541588</td>\n",
              "      <td>66.110710</td>\n",
              "      <td>66.403412</td>\n",
              "      <td>61.932362</td>\n",
              "      <td>59.820030</td>\n",
              "      <td>59.766552</td>\n",
              "      <td>61.722721</td>\n",
              "      <td>87.942314</td>\n",
              "      <td>103.457596</td>\n",
              "      <td>120.115753</td>\n",
              "      <td>119.355858</td>\n",
              "      <td>118.819733</td>\n",
              "      <td>121.403900</td>\n",
              "      <td>121.271057</td>\n",
              "      <td>120.592201</td>\n",
              "      <td>117.588142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>186</td>\n",
              "      <td>46.693031</td>\n",
              "      <td>51.026253</td>\n",
              "      <td>50.998386</td>\n",
              "      <td>53.253906</td>\n",
              "      <td>57.908436</td>\n",
              "      <td>57.817554</td>\n",
              "      <td>60.681244</td>\n",
              "      <td>50.930050</td>\n",
              "      <td>57.347900</td>\n",
              "      <td>117.491058</td>\n",
              "      <td>152.579834</td>\n",
              "      <td>150.560410</td>\n",
              "      <td>142.475555</td>\n",
              "      <td>122.137939</td>\n",
              "      <td>96.462257</td>\n",
              "      <td>95.549095</td>\n",
              "      <td>108.646088</td>\n",
              "      <td>128.392899</td>\n",
              "      <td>144.032623</td>\n",
              "      <td>128.787842</td>\n",
              "      <td>78.568977</td>\n",
              "      <td>80.913757</td>\n",
              "      <td>91.223732</td>\n",
              "      <td>89.978043</td>\n",
              "      <td>76.308357</td>\n",
              "      <td>74.279686</td>\n",
              "      <td>74.957108</td>\n",
              "      <td>76.945312</td>\n",
              "      <td>50.283966</td>\n",
              "      <td>49.949829</td>\n",
              "      <td>50.258877</td>\n",
              "      <td>51.861835</td>\n",
              "      <td>58.926815</td>\n",
              "      <td>70.545502</td>\n",
              "      <td>82.679390</td>\n",
              "      <td>84.955956</td>\n",
              "      <td>87.640892</td>\n",
              "      <td>99.015854</td>\n",
              "      <td>125.383865</td>\n",
              "      <td>...</td>\n",
              "      <td>147.313339</td>\n",
              "      <td>155.302002</td>\n",
              "      <td>159.340057</td>\n",
              "      <td>109.716042</td>\n",
              "      <td>119.592911</td>\n",
              "      <td>114.808075</td>\n",
              "      <td>101.501793</td>\n",
              "      <td>96.266281</td>\n",
              "      <td>95.919296</td>\n",
              "      <td>88.727264</td>\n",
              "      <td>94.355537</td>\n",
              "      <td>107.336464</td>\n",
              "      <td>99.585968</td>\n",
              "      <td>95.346176</td>\n",
              "      <td>92.200027</td>\n",
              "      <td>89.344910</td>\n",
              "      <td>88.548973</td>\n",
              "      <td>116.687256</td>\n",
              "      <td>132.474518</td>\n",
              "      <td>126.400520</td>\n",
              "      <td>115.272522</td>\n",
              "      <td>74.230095</td>\n",
              "      <td>120.017113</td>\n",
              "      <td>130.189850</td>\n",
              "      <td>135.077133</td>\n",
              "      <td>134.406769</td>\n",
              "      <td>133.537750</td>\n",
              "      <td>131.888794</td>\n",
              "      <td>140.653152</td>\n",
              "      <td>151.938370</td>\n",
              "      <td>174.695343</td>\n",
              "      <td>175.560883</td>\n",
              "      <td>116.905655</td>\n",
              "      <td>112.465393</td>\n",
              "      <td>101.011795</td>\n",
              "      <td>100.116196</td>\n",
              "      <td>104.111008</td>\n",
              "      <td>100.631760</td>\n",
              "      <td>98.731766</td>\n",
              "      <td>99.631287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>135</td>\n",
              "      <td>69.723122</td>\n",
              "      <td>71.743423</td>\n",
              "      <td>75.124985</td>\n",
              "      <td>74.212280</td>\n",
              "      <td>71.575027</td>\n",
              "      <td>73.013824</td>\n",
              "      <td>73.763290</td>\n",
              "      <td>69.420685</td>\n",
              "      <td>65.376129</td>\n",
              "      <td>64.034233</td>\n",
              "      <td>54.535965</td>\n",
              "      <td>46.021946</td>\n",
              "      <td>34.277691</td>\n",
              "      <td>32.140850</td>\n",
              "      <td>41.412891</td>\n",
              "      <td>52.945950</td>\n",
              "      <td>60.709576</td>\n",
              "      <td>61.123837</td>\n",
              "      <td>60.253109</td>\n",
              "      <td>62.702049</td>\n",
              "      <td>63.206799</td>\n",
              "      <td>61.179913</td>\n",
              "      <td>59.687401</td>\n",
              "      <td>57.966797</td>\n",
              "      <td>39.604385</td>\n",
              "      <td>13.569821</td>\n",
              "      <td>18.822058</td>\n",
              "      <td>10.439944</td>\n",
              "      <td>63.328609</td>\n",
              "      <td>69.666275</td>\n",
              "      <td>66.326309</td>\n",
              "      <td>70.063263</td>\n",
              "      <td>70.648613</td>\n",
              "      <td>69.281372</td>\n",
              "      <td>68.798019</td>\n",
              "      <td>67.467758</td>\n",
              "      <td>66.630669</td>\n",
              "      <td>65.803894</td>\n",
              "      <td>59.072155</td>\n",
              "      <td>...</td>\n",
              "      <td>0.435062</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Width           0           1  ...         781         782         783\n",
              "0    139  110.821945  110.604362  ...   67.966774   68.516632   72.946121\n",
              "1    186   71.004395   79.708069  ...  133.476486  117.320969  112.165230\n",
              "2    181  120.460930  120.903580  ...  121.271057  120.592201  117.588142\n",
              "3    186   46.693031   51.026253  ...  100.631760   98.731766   99.631287\n",
              "4    135   69.723122   71.743423  ...    1.000000    1.000000    1.000000\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciUjF5tmdqLC",
        "outputId": "60975074-9f19-4fc3-9300-e6ab817043e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "Size=28\n",
        "qual_img=7\n",
        "L = Width[qual_img]\n",
        "data=np.array(df_size.drop('Width',axis=1).iloc[qual_img]).reshape(Size,Size)\n",
        "img = Image.fromarray(data.astype('uint8'), mode='L')\n",
        "img=np.float32(img)\n",
        "img28=cv2.resize(img,(Size,Size), interpolation = cv2.INTER_AREA)\n",
        "Foto=np.array(img28).reshape(28,28)\n",
        "plt.imshow(Foto, cmap = \"gray\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3ed61a5128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6UQexMtkz5t"
      },
      "source": [
        "df_getBetter = GetBetter(img)\n",
        "#df_getBetter = GetBetter(data)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRo2nqCJ09NP",
        "outputId": "78a8f5a5-8cbe-4222-bab7-123296c068cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_getBetter.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 730)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJgilCmz7I9A",
        "outputId": "57c015ad-befa-4cb5-8a54-8acf3459a803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "qual_img =21\n",
        "data=np.array(df_getBetter.drop('Width',axis=1).iloc[qual_img]).reshape(Size,Size)\n",
        "img = Image.fromarray(data.astype('uint8'), mode='L')\n",
        "img=np.float32(img)\n",
        "img28=cv2.resize(img,(Size,Size), interpolation = cv2.INTER_AREA)\n",
        "plt.imshow(img28, cmap = \"gray\")\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-0ddaff250e20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mqual_img\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_getBetter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Width'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqual_img\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg28\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 729 into shape (28,28)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DXbVnD5HaeO"
      },
      "source": [
        "plt.imshow(Foto, cmap = \"gray\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucryOhXfHcS1"
      },
      "source": [
        "plt.imshow(img28, cmap = \"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-MTA4fXg2W0"
      },
      "source": [
        "mean_value = np.mean(img)\n",
        "img_new = img.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbcfWPMdewq3"
      },
      "source": [
        "'''\n",
        "for i in range(28):\n",
        "  for j in range(28):\n",
        "    if img[i,j] < mean_value:\n",
        "      img_new[i,j] = 255\n",
        "    else:\n",
        "      img_new[i,j] = 0\n",
        "'''\n",
        "img28=cv2.resize(img_new,(Size,Size), interpolation = cv2.INTER_AREA)\n",
        "Foto=np.array(img28).reshape(28,28)\n",
        "plt.imshow(Foto, cmap = \"gray\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spRNBSwifDqQ"
      },
      "source": [
        "L = Width[qual_img]\n",
        "Area = np.sum(img_new) / (255.0 * 28 * 28)* L*L\n",
        "print(Area)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GP_DXsWibOX"
      },
      "source": [
        "Area_All, Diameter_All=PSDArea(df_size) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ydbrnjewBYL"
      },
      "source": [
        "df_size.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L3IfgxMs3dI"
      },
      "source": [
        "# print(Area_All)\n",
        "print(Diameter_All)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeLlypq5gbFa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJFWGVQJLwRo"
      },
      "source": [
        "diam = Diameter_All.copy()\n",
        "PSD_value = PSD(diam)\n",
        "print(PSD_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvked-F_kPwi"
      },
      "source": [
        "!git clone https://github.com/ucfilho/marquesgabi_out_2020\n",
        "%cd marquesgabi_out_2020\n",
        "PSD_imageJ = 'Areas_ImageJ.csv'\n",
        "df_imageJ = pd.read_csv(PSD_imageJ)\n",
        "print(df_imageJ.head(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "004Ki_RdzWqi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnmV_uagvrhZ"
      },
      "source": [
        "df_imageJ.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Fdww7M1KSx"
      },
      "source": [
        "PSD_new = PSD(PSD_new['Diam'])\n",
        "print(PSD_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oFgONgYxwp0"
      },
      "source": [
        "Diam = PSD_value # foto que esta fazendo\n",
        "Diam1 = PSD_new # imageJ\n",
        "\n",
        "plt.hist([Diam,Diam1], 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctf4oExeyz1B"
      },
      "source": [
        "Diam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKwv70Nty2jF"
      },
      "source": [
        "Diam1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQzLVpnv1VsG",
        "outputId": "8f369d50-9d10-4c9e-e7aa-1e6cd91fb7ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "730**0.5"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27.018512172212592"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pq4DTm1np4i"
      },
      "source": [
        ""
      ]
    }
  ]
}